{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ot\n",
    "import torch\n",
    "from math import sqrt\n",
    "\n",
    "from aux_functions import *\n",
    "from TheGAN import LevyGAN\n",
    "import configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# print(read_serial_number(\"model_G1_D1_gp_Hsym_4d_62noise\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP TIME: 0.5199230300004274\n",
      "MAKE Z 1 TIME: 0.0037576189997707843\n",
      "netG 1 TIME: 0.10290303900001163\n",
      "GRAD PENALTY TIME: 0.08061694400021224\n",
      "netD 1 twice TIME: 0.21339746600006038\n",
      "BEFORE BACKPROP TIME: 0.0009930470005201641\n",
      "netD BACKPROP TIME: 0.27960391499982507\n",
      "OPT D TIME: 0.005824068000038096\n",
      "MAKE Z 2 TIME: 0.0007363430004261318\n",
      "netG 2 TIME: 0.015317860999857658\n",
      "netD 2 TIME: 0.14461714299977757\n",
      "netG BACKPROP TIME: 0.2856110960001388\n",
      "OPT G TIME: 0.0039450820004276466\n",
      "BEFORE TESTS TIME: 1.9090002751909196e-06\n",
      "UNFIXED PART OF REPORT TIME: 0.730849028999728\n",
      "CHEN ERRORS TIME: 0.14214899399939895\n",
      "FIXED ERRORS TIME: 0.6604643509999732\n",
      "ST DEV ERRORS TIME: 0.015056294000714843\n",
      "JOINT WASS ERRORS TIME: 6.847290087000147\n",
      "AFTER TESTS TIME: 0.035931970000092406\n",
      "ep: 0/2, itr: 0, discr grad norm:  0.59007, discr loss: -14.61860, joint err:  0.45013, st dev err:  0.14545\n",
      "errs: ['0.0767', '0.0632', '0.0916', '0.0720', '0.1215', '0.0769'], chen errs: ['0.4365', '0.4383', '0.1456', '0.4575', '0.1506', '0.1535']\n",
      "AFTER REPORT TIME: 0.00017046799985109828\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "SAVING DICTS TIME: 0.025413555000341148\n",
      "ep: 0/2, itr: 100, discr grad norm:  0.00272, discr loss: -14.99793, joint err:  0.44639, st dev err:  0.14588\n",
      "errs: ['0.0799', '0.0661', '0.0951', '0.0731', '0.1273', '0.0822'], chen errs: ['0.4335', '0.4361', '0.1372', '0.4508', '0.1486', '0.1467']\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 200, discr grad norm:  0.00066, discr loss: -14.99935, joint err:  0.44871, st dev err:  0.14521\n",
      "errs: ['0.0769', '0.0682', '0.0991', '0.0710', '0.1267', '0.0845'], chen errs: ['0.4310', '0.4359', '0.1395', '0.4454', '0.1458', '0.1444']\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 300, discr grad norm:  0.00030, discr loss: -14.99968, joint err:  0.44856, st dev err:  0.14598\n",
      "errs: ['0.0774', '0.0657', '0.0957', '0.0700', '0.1277', '0.0824'], chen errs: ['0.4389', '0.4270', '0.1357', '0.4412', '0.1393', '0.1393']\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 400, discr grad norm:  0.01134, discr loss: -14.99025, joint err:  0.45051, st dev err:  0.14400\n",
      "errs: ['0.0634', '0.0468', '0.0933', '0.0691', '0.1181', '0.0777'], chen errs: ['0.4471', '0.4465', '0.1461', '0.4503', '0.1507', '0.1455']\n",
      "Saved parameters (fixed error)\n",
      "ep: 0/2, itr: 500, discr grad norm:  0.00012, discr loss: -14.99988, joint err:  0.45107, st dev err:  0.14447\n",
      "errs: ['0.0651', '0.0524', '0.0915', '0.0663', '0.1182', '0.0781'], chen errs: ['0.4428', '0.4532', '0.1466', '0.4433', '0.1489', '0.1465']\n",
      "ep: 0/2, itr: 600, discr grad norm:  0.00007, discr loss: -14.99992, joint err:  0.44700, st dev err:  0.14422\n",
      "errs: ['0.0644', '0.0490', '0.0909', '0.0681', '0.1169', '0.0765'], chen errs: ['0.4414', '0.4505', '0.1389', '0.4503', '0.1525', '0.1453']\n",
      "Saved parameters (fixed error)\n",
      "ep: 0/2, itr: 700, discr grad norm:  0.00006, discr loss: -14.99994, joint err:  0.45053, st dev err:  0.14396\n",
      "errs: ['0.0630', '0.0497', '0.0899', '0.0664', '0.1156', '0.0768'], chen errs: ['0.4485', '0.4595', '0.1480', '0.4517', '0.1557', '0.1505']\n",
      "Saved parameters (fixed error)\n",
      "ep: 0/2, itr: 800, discr grad norm:  0.00003, discr loss: -14.99997, joint err:  0.44679, st dev err:  0.14427\n",
      "errs: ['0.0621', '0.0465', '0.0881', '0.0672', '0.1148', '0.0738'], chen errs: ['0.4467', '0.4471', '0.1411', '0.4488', '0.1482', '0.1444']\n",
      "Saved parameters (fixed error)\n",
      "ep: 0/2, itr: 900, discr grad norm:  0.00008, discr loss: -14.99993, joint err:  0.43452, st dev err:  0.14285\n",
      "errs: ['0.0508', '0.0616', '0.0834', '0.0520', '0.1040', '0.0754'], chen errs: ['0.4524', '0.4402', '0.1528', '0.4665', '0.1611', '0.1514']\n",
      "Saved parameters (fixed error)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m levG \u001B[38;5;241m=\u001B[39m LevyGAN(config)\n\u001B[1;32m      6\u001B[0m levG\u001B[38;5;241m.\u001B[39mload_dicts_unstructured(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_saves/GAN1_4d_62noise_min_chen_GREAT_Hsymgenerator.pt\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_saves/GAN1_4d_62noise_min_chen_GREAT_Hsymdiscriminator.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m \u001B[43mlevG\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassic_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/TheGAN.py:426\u001B[0m, in \u001B[0;36mLevyGAN.classic_train\u001B[0;34m(self, tr_conf)\u001B[0m\n\u001B[1;32m    423\u001B[0m     loss_d \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m gradient_penalty\n\u001B[1;32m    425\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_time(description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBEFORE BACKPROP\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 426\u001B[0m \u001B[43mloss_d\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_time(description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnetD BACKPROP\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    428\u001B[0m opt_d\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "config = configs.config\n",
    "\n",
    "training_config = configs.training_config\n",
    "\n",
    "levG = LevyGAN(config)\n",
    "levG.load_dicts_unstructured('model_saves/GAN1_4d_62noise_min_chen_GREAT_Hsymgenerator.pt','model_saves/GAN1_4d_62noise_min_chen_GREAT_Hsymdiscriminator.pt')\n",
    "levG.classic_train(training_config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
