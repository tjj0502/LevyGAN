{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ot\n",
    "import torch\n",
    "from math import sqrt\n",
    "\n",
    "from aux_functions import *\n",
    "from TheGAN import LevyGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(read_serial_number(\"model_G1_D1_gp_Hsym_4d_62noise\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blub\n",
      "TOP TIME: 0.23901198900057352\n",
      "BEFORE REPORT TIME: 0.5757330289998208\n",
      "UNFIXED PART OF REPORT TIME: 0.4352646109982743\n",
      "CHEN ERRORS TIME: 0.09678175199951511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andy/anaconda3/envs/GAN/lib/python3.10/site-packages/ot/lp/solver_1d.py:41: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484746364/work/aten/src/ATen/native/TensorShape.cpp:2981.)\n",
      "  cws = cws.T.contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIXED ERRORS TIME: 0.44282328100234736\n",
      "ST DEV ERRORS TIME: 0.006902449000335764\n",
      "JOINT WASS ERRORS TIME: 0.16173897300177487\n",
      "epoch: 0/2, iter: 0, gradient norm: 0.65301, discriminator dist: -14.39925, st_dev error:  0.13454, joint_wass_dist:  0.51896\n",
      "errs: ['0.0289', '0.0314', '0.0286', '0.0345', '0.0418', '0.0266'], ch_err: ['0.4980', '0.4954', '0.2218', '0.4792', '0.1991', '0.2063'] \n",
      "==== REPORT TIME: 0.024101723000057973\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "SAVING DICTS TIME: 0.014503771999443416\n",
      "TOP TIME: 0.00035082899921690114\n",
      "TOP TIME: 0.26685843199811643\n",
      "TOP TIME: 0.25256435600022087\n",
      "TOP TIME: 0.24869164700066904\n",
      "TOP TIME: 0.25358253000013065\n",
      "TOP TIME: 0.4827284809980483\n",
      "TOP TIME: 0.2554810510009702\n",
      "TOP TIME: 0.24650857600136078\n",
      "TOP TIME: 0.2455877119973593\n",
      "TOP TIME: 0.24113322400080506\n",
      "TOP TIME: 0.46353940699918894\n",
      "TOP TIME: 0.2602506160001212\n",
      "TOP TIME: 0.24546834700231557\n",
      "TOP TIME: 0.24198169699957361\n",
      "TOP TIME: 0.24138324400337297\n",
      "TOP TIME: 0.45850018999772146\n",
      "TOP TIME: 0.2504860570006713\n",
      "TOP TIME: 0.247389274998568\n",
      "TOP TIME: 0.24426809099895763\n",
      "TOP TIME: 0.24827630399886402\n",
      "TOP TIME: 0.4709374270023545\n",
      "TOP TIME: 0.24937655399844516\n",
      "TOP TIME: 0.25191619800170884\n",
      "TOP TIME: 0.2437860880017979\n",
      "TOP TIME: 0.24511580200123717\n",
      "TOP TIME: 0.4691231689976121\n",
      "TOP TIME: 0.24895040900082677\n",
      "TOP TIME: 0.2559693149996747\n",
      "TOP TIME: 0.24231085800056462\n",
      "TOP TIME: 0.274199953997595\n",
      "TOP TIME: 0.5539843029982876\n",
      "TOP TIME: 0.3025797100017371\n",
      "TOP TIME: 0.28704921000098693\n",
      "TOP TIME: 0.294181696997839\n",
      "TOP TIME: 0.2604572829986864\n",
      "TOP TIME: 0.5179746079993492\n",
      "TOP TIME: 0.29464275499776704\n",
      "TOP TIME: 0.27221201400243444\n",
      "TOP TIME: 0.2830245430013747\n",
      "TOP TIME: 0.28183660300055635\n",
      "TOP TIME: 0.5032263549983327\n",
      "TOP TIME: 0.2518752420000965\n",
      "TOP TIME: 0.2723331640008837\n",
      "TOP TIME: 0.27724382399901515\n",
      "TOP TIME: 0.2669436640026106\n",
      "TOP TIME: 0.507744697999442\n",
      "TOP TIME: 0.2596146600008069\n",
      "TOP TIME: 0.24625779900088673\n",
      "TOP TIME: 0.24445891099821893\n",
      "TOP TIME: 0.2462460460010334\n",
      "TOP TIME: 0.4641713320015697\n",
      "TOP TIME: 0.2592629280006804\n",
      "TOP TIME: 0.2492729870027688\n",
      "TOP TIME: 0.2472071699994558\n",
      "TOP TIME: 0.25469206100024167\n",
      "TOP TIME: 0.5127424749989586\n",
      "TOP TIME: 0.3295382119977148\n",
      "TOP TIME: 0.2749984020010743\n",
      "TOP TIME: 0.25558788900161744\n",
      "TOP TIME: 0.2491620030014019\n",
      "TOP TIME: 0.4733025159985118\n",
      "TOP TIME: 0.25181734500074526\n",
      "TOP TIME: 0.25189222800327116\n",
      "TOP TIME: 0.2904690559989831\n",
      "TOP TIME: 0.3679015759989852\n",
      "TOP TIME: 0.4939246390022163\n",
      "TOP TIME: 0.3421086859998468\n",
      "TOP TIME: 0.29688880300091114\n",
      "TOP TIME: 0.2574369089998072\n",
      "TOP TIME: 0.2539914970002428\n",
      "TOP TIME: 0.5473710689984728\n",
      "TOP TIME: 0.2934884360001888\n",
      "TOP TIME: 0.2620061820016417\n",
      "TOP TIME: 0.2472832509993168\n",
      "TOP TIME: 0.25478741800179705\n",
      "TOP TIME: 0.5997395379999944\n",
      "TOP TIME: 0.31623102700177697\n",
      "TOP TIME: 0.28681100999892806\n",
      "TOP TIME: 0.3062378479990002\n",
      "TOP TIME: 0.32777141500264406\n",
      "TOP TIME: 0.5466871270000411\n",
      "TOP TIME: 0.32567229499909445\n",
      "TOP TIME: 0.32859355099935783\n",
      "TOP TIME: 0.30363258400029736\n",
      "TOP TIME: 0.29508922699824325\n",
      "TOP TIME: 0.6146431710003526\n",
      "TOP TIME: 0.3958788190029736\n",
      "TOP TIME: 0.3278929150001204\n",
      "TOP TIME: 0.3060039529991627\n",
      "TOP TIME: 0.29144862400062266\n",
      "TOP TIME: 0.5781208600019454\n",
      "TOP TIME: 0.35654298499866854\n",
      "TOP TIME: 0.3302256560018577\n",
      "TOP TIME: 0.468558069998835\n",
      "TOP TIME: 0.45262780300254235\n",
      "TOP TIME: 0.6596233670024958\n",
      "TOP TIME: 0.36127337899961276\n",
      "TOP TIME: 0.3417915030004224\n",
      "TOP TIME: 0.3088588049977261\n",
      "TOP TIME: 0.29721748400334036\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 47>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     45\u001B[0m levG \u001B[38;5;241m=\u001B[39m LevyGAN(config)\n\u001B[1;32m     46\u001B[0m levG\u001B[38;5;241m.\u001B[39mload_dicts_unstructured(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_saves/GAN1_4d_62noise_min_sum_AMAZING_Hsymgenerator.pt\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_saves/GAN1_4d_62noise_min_sum_AMAZING_Hsymdiscriminator.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 47\u001B[0m \u001B[43mlevG\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassic_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/TheGAN.py:441\u001B[0m, in \u001B[0;36mLevyGAN.classic_train\u001B[0;34m(self, tr_conf)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mLipschitz_mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgp\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    440\u001B[0m     loss_d \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m gradient_penalty\n\u001B[0;32m--> 441\u001B[0m \u001B[43mloss_d\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    442\u001B[0m opt_d\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m    444\u001B[0m \u001B[38;5;66;03m# train Generator with probability 1/5\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/_tensor.py:396\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    389\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    390\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    394\u001B[0m         create_graph\u001B[38;5;241m=\u001B[39mcreate_graph,\n\u001B[1;32m    395\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs)\n\u001B[0;32m--> 396\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    168\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    170\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    171\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 173\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    174\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'device': torch.device('cpu'),\n",
    "    'ngpu': 0,\n",
    "    'w dim': 4,\n",
    "    'a dim': 6,\n",
    "    'noise size': 62,\n",
    "    'which generator': 1,\n",
    "    'which discriminator': 1,\n",
    "    'generator symmetry mode': 'Hsym',\n",
    "    'generator last width': 6,\n",
    "    's dim': 16,\n",
    "    'leakyReLU slope': 0.2,\n",
    "    'num epochs': 20,\n",
    "    'num Chen iters': 5000,\n",
    "    'optimizer': 'Adam',\n",
    "    'lrG': 0.0001,\n",
    "    'lrD': 0.0005,\n",
    "    'beta1': 0,\n",
    "    'beta2': 0.99,\n",
    "    'Lipschitz mode': 'gp',\n",
    "    'weight clipping limit': 0.01,\n",
    "    'gp weight': 10.0,\n",
    "    'batch size': 1024,\n",
    "    'test batch size': 16384,\n",
    "    'unfixed test batch size': 4096,\n",
    "    'num tests for 2d': 8,\n",
    "    'W fixed whole': [1.0, -0.5, -1.2, -0.3, 0.7, 0.2, -0.9, 0.1, 1.7],\n",
    "    'do timeing': False\n",
    "}\n",
    "\n",
    "training_config = {\n",
    "    'num epochs': 2,\n",
    "    'num Chen iters': 5000,\n",
    "    'optimizer': 'Adam',\n",
    "    'lrG': 0.0001,\n",
    "    'lrD': 0.0005,\n",
    "    'beta1': 0,\n",
    "    'beta2': 0.99,\n",
    "    'Lipschitz mode': 'gradient penalty',\n",
    "    'weight clipping limit': 0.01,\n",
    "    'gp weight': 10.0,\n",
    "    'batch size': 1024,\n",
    "}\n",
    "\n",
    "levG = LevyGAN(config)\n",
    "levG.load_dicts_unstructured('model_saves/GAN1_4d_62noise_min_sum_AMAZING_Hsymgenerator.pt','model_saves/GAN1_4d_62noise_min_sum_AMAZING_Hsymdiscriminator.pt')\n",
    "levG.classic_train(training_config)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
