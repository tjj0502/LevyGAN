{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ot\n",
    "import torch\n",
    "from math import sqrt\n",
    "\n",
    "from aux_functions import *\n",
    "from TheGAN import LevyGAN\n",
    "import configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# print(read_serial_number(\"model_G1_D1_gp_Hsym_4d_62noise\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0/2, itr: 0, discr grad norm:  0.07797, discr loss: -7.93461, st dev err:  0.14012\n",
      "errs: ['0.0671', '0.0372', '0.0386', '0.0381', '0.0692', '0.1017'], chen errs: ['0.5462', '0.5304', '0.2460', '0.5269', '0.2695', '0.3188']\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 5, discr grad norm:  0.07780, discr loss: -8.61303, st dev err:  0.13833\n",
      "errs: ['0.0568', '0.0342', '0.0294', '0.0333', '0.0617', '0.0925'], chen errs: ['0.5473', '0.5302', '0.2343', '0.5198', '0.2632', '0.3067']\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 10, discr grad norm:  0.07535, discr loss: -9.17908, st dev err:  0.13804\n",
      "errs: ['0.0519', '0.0327', '0.0283', '0.0331', '0.0508', '0.0817'], chen errs: ['0.5311', '0.5154', '0.2250', '0.5264', '0.2555', '0.2973']\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 15, discr grad norm:  0.07703, discr loss: -9.69848, st dev err:  0.13552\n",
      "errs: ['0.0447', '0.0300', '0.0268', '0.0300', '0.0441', '0.0743'], chen errs: ['0.5344', '0.5048', '0.2248', '0.5080', '0.2497', '0.2862']\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 20, discr grad norm:  0.07325, discr loss: -10.05563, st dev err:  0.13544\n",
      "errs: ['0.0420', '0.0299', '0.0286', '0.0300', '0.0363', '0.0661'], chen errs: ['0.5233', '0.5129', '0.2192', '0.5036', '0.2398', '0.2764']\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 25, discr grad norm:  0.07084, discr loss: -10.49438, st dev err:  0.13514\n",
      "errs: ['0.0377', '0.0303', '0.0288', '0.0290', '0.0336', '0.0608'], chen errs: ['0.5233', '0.4973', '0.2127', '0.5021', '0.2353', '0.2680']\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 30, discr grad norm:  0.06977, discr loss: -10.85769, st dev err:  0.13411\n",
      "errs: ['0.0348', '0.0301', '0.0304', '0.0316', '0.0277', '0.0514'], chen errs: ['0.5164', '0.4911', '0.2045', '0.5055', '0.2315', '0.2691']\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 35, discr grad norm:  0.06520, discr loss: -11.16175, st dev err:  0.13516\n",
      "errs: ['0.0313', '0.0311', '0.0310', '0.0318', '0.0273', '0.0516'], chen errs: ['0.5063', '0.4832', '0.2085', '0.4960', '0.2331', '0.2638']\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 40, discr grad norm:  0.06553, discr loss: -11.49795, st dev err:  0.13454\n",
      "errs: ['0.0294', '0.0346', '0.0336', '0.0331', '0.0259', '0.0488'], chen errs: ['0.5025', '0.4912', '0.2095', '0.4954', '0.2352', '0.2581']\n",
      "ep: 0/2, itr: 45, discr grad norm:  0.05781, discr loss: -11.68874, st dev err:  0.13399\n",
      "errs: ['0.0285', '0.0358', '0.0342', '0.0349', '0.0240', '0.0444'], chen errs: ['0.5065', '0.4849', '0.2060', '0.4820', '0.2271', '0.2560']\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 50, discr grad norm:  0.06195, discr loss: -12.00472, st dev err:  0.13418\n",
      "errs: ['0.0301', '0.0368', '0.0350', '0.0375', '0.0268', '0.0435'], chen errs: ['0.5036', '0.4872', '0.2058', '0.4845', '0.2239', '0.2467']\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 55, discr grad norm:  0.05133, discr loss: -12.21642, st dev err:  0.13421\n",
      "errs: ['0.0294', '0.0339', '0.0361', '0.0355', '0.0271', '0.0395'], chen errs: ['0.4958', '0.4819', '0.1967', '0.4819', '0.2202', '0.2500']\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 60, discr grad norm:  0.05335, discr loss: -12.47312, st dev err:  0.13440\n",
      "errs: ['0.0284', '0.0359', '0.0371', '0.0341', '0.0276', '0.0384'], chen errs: ['0.4881', '0.4756', '0.1978', '0.4854', '0.2169', '0.2385']\n",
      "Saved parameters (fixed error)\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 65, discr grad norm:  0.05042, discr loss: -12.62253, st dev err:  0.13494\n",
      "errs: ['0.0311', '0.0362', '0.0378', '0.0377', '0.0292', '0.0358'], chen errs: ['0.4908', '0.4771', '0.2019', '0.4804', '0.2205', '0.2378']\n",
      "ep: 0/2, itr: 70, discr grad norm:  0.05056, discr loss: -12.81198, st dev err:  0.13474\n",
      "errs: ['0.0332', '0.0384', '0.0377', '0.0387', '0.0306', '0.0360'], chen errs: ['0.4863', '0.4756', '0.1960', '0.4809', '0.2152', '0.2437']\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 75, discr grad norm:  0.04294, discr loss: -12.94697, st dev err:  0.13517\n",
      "errs: ['0.0326', '0.0414', '0.0369', '0.0399', '0.0293', '0.0356'], chen errs: ['0.4911', '0.4763', '0.1934', '0.4838', '0.2155', '0.2361']\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 80, discr grad norm:  0.04553, discr loss: -13.14314, st dev err:  0.13497\n",
      "errs: ['0.0311', '0.0413', '0.0376', '0.0401', '0.0318', '0.0329'], chen errs: ['0.4921', '0.4734', '0.1990', '0.4819', '0.2105', '0.2291']\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 85, discr grad norm:  0.03668, discr loss: -13.28188, st dev err:  0.13596\n",
      "errs: ['0.0332', '0.0376', '0.0379', '0.0394', '0.0330', '0.0344'], chen errs: ['0.4831', '0.4736', '0.2020', '0.4731', '0.2051', '0.2268']\n",
      "Saved parameters (chen errors)\n",
      "ep: 0/2, itr: 90, discr grad norm:  0.04152, discr loss: -13.39474, st dev err:  0.13533\n",
      "errs: ['0.0327', '0.0416', '0.0401', '0.0411', '0.0349', '0.0304'], chen errs: ['0.4865', '0.4716', '0.2027', '0.4791', '0.2086', '0.2339']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m levG \u001B[38;5;241m=\u001B[39m LevyGAN(serial_num_in\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# levG.load_dicts_unstructured('model_saves/GAN1_4d_62noise_min_chen_GREAT_Hsymgenerator.pt','model_saves/GAN1_4d_62noise_min_chen_GREAT_Hsymdiscriminator.pt')\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[43mlevG\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassic_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/TheGAN.py:464\u001B[0m, in \u001B[0;36mLevyGAN.classic_train\u001B[0;34m(self, tr_conf_in)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m iters \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    463\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_time(description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBEFORE TESTS\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 464\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_tests\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcomp_joint_err\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompute_joint_error\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_time(description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAFTER TESTS\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    466\u001B[0m     report \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_report(epoch\u001B[38;5;241m=\u001B[39mepoch, iters\u001B[38;5;241m=\u001B[39miters)\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/TheGAN.py:216\u001B[0m, in \u001B[0;36mLevyGAN.do_tests\u001B[0;34m(self, comp_joint_err)\u001B[0m\n\u001B[1;32m    213\u001B[0m gradient_penalty, gradient_norm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_penalty(data, pruned_fake_data, gp_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    215\u001B[0m prob_real \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnetD(data)\n\u001B[0;32m--> 216\u001B[0m prob_fake \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnetD\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfake_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m loss_d_fake \u001B[38;5;241m=\u001B[39m prob_fake\u001B[38;5;241m.\u001B[39mmean(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    219\u001B[0m loss_d_real \u001B[38;5;241m=\u001B[39m prob_real\u001B[38;5;241m.\u001B[39mmean(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/LevyGAN/Discriminator.py:11\u001B[0m, in \u001B[0;36mDiscriminator.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 139\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "config = configs.config\n",
    "\n",
    "training_config = configs.training_config\n",
    "\n",
    "levG = LevyGAN(serial_num_in=2)\n",
    "# levG.load_dicts_unstructured('model_saves/GAN1_4d_62noise_min_chen_GREAT_Hsymgenerator.pt','model_saves/GAN1_4d_62noise_min_chen_GREAT_Hsymdiscriminator.pt')\n",
    "levG.classic_train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
