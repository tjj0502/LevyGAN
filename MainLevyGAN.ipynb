{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import copy\n",
    "from math import sqrt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "To cite:\n",
    "\n",
    "J. M. C. Clark and R. J. Cameron. The maximum rate of convergence of discrete approximations for Stochastic differential equations. in Stochastic Differential Systems Filtering and Control, ed. by Grigelionis (Springer, Berlin), 1980.\n",
    "A. S. Dickinson. Optimal Approximation of the Second Iterated Integral of Brownian Motion. Stochastic Analysis and Applications, 25(5):1109{1128, 2007.\n",
    "\n",
    "F. Kastner, A. Rößler. \"An Analysis of Approximation Algorithms for Iterated Stochastic Integrals and a Julia and Matlab Simulation Toolbox\". arXiv:2201.08424\n",
    "\n",
    "Foster, J. M. Numerical Approximations for Stochastic Differential Equations. University of Oxford, 2020."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "noise_size = 32\n",
    "\n",
    "# Number of training epochs using classical training\n",
    "num_epochs = 15\n",
    "\n",
    "# Number of iterations of Chen training\n",
    "num_Chen_iters = 5000\n",
    "\n",
    "# 'Adam' of 'RMSProp'\n",
    "which_optimizer = 'RMSProp'\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.00002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "ngpu = 0\n",
    "\n",
    "# To keep the criterion Lipschitz\n",
    "weight_cliping_limit = 0.01\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "test_batch_size = 65536\n",
    "\n",
    "w_dim = 4\n",
    "\n",
    "a_dim = int(w_dim*(w_dim - 1)//2)\n",
    "\n",
    "# if 1 use GAN1, if 2 use GAN2, etc.\n",
    "which_model = 2\n",
    "\n",
    "# slope for LeakyReLU\n",
    "leakyReLU_slope = 0.2\n",
    "\n",
    "# this gives the option to rum the training process multiple times with differently initialised GANs\n",
    "num_trials = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# CHEN RELATION\n",
    "# Levy-area satisfies a version of the Chen relation (see Chen_relation.pdf) and is the unique distribution which satisfies this version of the relation\n",
    "\n",
    "def chen_combine(w_a_in: torch.TensorType):\n",
    "    # the batch dimension of the inputs will be quartered\n",
    "    out_size = w_a_in.size(0)//2\n",
    "    assert 2*out_size == w_a_in.size(0)\n",
    "    assert w_a_in.size(1) == w_dim + a_dim\n",
    "\n",
    "    # w_0_s is from 0 to t/2 and w_s_t is from t/2 to t\n",
    "    w_0_s,w_s_t = w_a_in.chunk(2)\n",
    "    result = torch.clone(w_0_s + w_s_t)\n",
    "    result[:,:w_dim] = sqrt(0.5)*result[:,:w_dim]\n",
    "    result[:,w_dim:(w_dim+a_dim)] = 0.5*result[:,w_dim:(w_dim+a_dim)]\n",
    "\n",
    "    idx = w_dim\n",
    "    for k in range(w_dim - 1):\n",
    "        for l in range(k+1,w_dim):\n",
    "            correction_term = 0.25*(w_0_s[:,k]*w_s_t[:,l] - w_0_s[:,l]*w_s_t[:,k])\n",
    "            result[:,idx] += correction_term\n",
    "            idx += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "# prints the 2-Wasserstein distances (in each of the Levy-area dimensions) between the input and chen_combine(chen_combine(input))\n",
    "# The idea behind this is that Levy-area is the unique distribution which is close to chen_combine of itself\n",
    "# Indeed this is experimentally confirmed in test.ipynb\n",
    "\n",
    "def chen_error_2step(w_a_in: torch.TensorType):\n",
    "    combined_data = chen_combine(w_a_in)\n",
    "    combined_data = chen_combine(combined_data)\n",
    "    return [sqrt(ot.wasserstein_1d(combined_data[:,w_dim+i],w_a_in[:,w_dim+i],p=2)) for i in range(a_dim)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# create dataloader for samples\n",
    "\n",
    "def row_processer(row):\n",
    "    return np.array(row, dtype= np.float32)\n",
    "\n",
    "filename = f\"samples/samples_{w_dim}-dim.csv\"\n",
    "datapipe = dp.iter.FileOpener([filename], mode='b')\n",
    "datapipe = datapipe.parse_csv(delimiter=',')\n",
    "datapipe = datapipe.map(row_processer)\n",
    "dataloader = DataLoader(dataset=datapipe, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "# Check if the dimensions match\n",
    "d = next(iter(dataloader))\n",
    "if d.size(1) != a_dim + w_dim:\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!! WRONG DATA DIMENSIONS !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    if classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# GAN 1\n",
    "\n",
    "class Generator1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator1, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim+noise_size,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,a_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class Discriminator1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator1, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim + a_dim,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(512,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(512,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# GAN 2\n",
    "\n",
    "class Generator2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator2, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim+noise_size,1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(1024,1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(1024,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512,a_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "\n",
    "class Discriminator2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator2, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim + a_dim,1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(1024,1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(1024,256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(256,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GAN 3\n",
    "\n",
    "class Generator3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator1, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim+noise_size,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(128,a_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class Discriminator3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator1, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim + a_dim,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(512,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Generator2(\n  (main): Sequential(\n    (0): Linear(in_features=36, out_features=1024, bias=True)\n    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Linear(in_features=1024, out_features=1024, bias=True)\n    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Linear(in_features=1024, out_features=512, bias=True)\n    (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU()\n    (9): Linear(in_features=512, out_features=6, bias=True)\n  )\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize nets\n",
    "if which_model == 1:\n",
    "    netD = Discriminator1().to(device)\n",
    "    netG = Generator1().to(device)\n",
    "elif which_model == 2:\n",
    "    netD = Discriminator2().to(device)\n",
    "    netG = Generator2().to(device)\n",
    "\n",
    "\n",
    "netD.apply(weights_init)\n",
    "netG.apply(weights_init)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Initialise optimiser\n",
    "\n",
    "if which_optimizer == 'Adam':\n",
    "    optG = torch.optim.Adam(netG.parameters(),lr = lr, betas=(beta1,0.999))\n",
    "    optD = torch.optim.Adam(netD.parameters(), lr = lr, betas=(beta1,0.999))\n",
    "elif which_optimizer == 'RMSProp':\n",
    "    optG = torch.optim.RMSprop(netG.parameters(), lr = lr)\n",
    "    optD = torch.optim.RMSprop(netD.parameters(), lr = lr)\n",
    "\n",
    "# A fixed W increment for testing purposes\n",
    "W_fixed: torch.Tensor = torch.tensor([1.0,-0.5,-1.2,-0.3,0.7,0.2,-0.9,0.1,1.7])\n",
    "\n",
    "\n",
    "W_fixed = W_fixed[:w_dim].unsqueeze(1).transpose(1,0)\n",
    "W_fixed = W_fixed.expand((test_batch_size,w_dim))\n",
    "\n",
    "# Load \"true\" samples generated from this fixed W increment\n",
    "test_filename = f\"samples/fixed_samples_{w_dim}-dim.csv\"\n",
    "A_fixed_true = np.genfromtxt(test_filename,dtype=float,delimiter=',',)\n",
    "A_fixed_true = A_fixed_true[:,w_dim:(w_dim+a_dim)]\n",
    "\n",
    "wass_errors = []\n",
    "chen_errors = []\n",
    "\n",
    "iters = 0\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Early stopping setup\n",
    "\n",
    "# Will have two backup points:\n",
    "# One where the sum of Wasserstein errors was minimal and one where the max was minimal\n",
    "\n",
    "min_sum = float('inf')\n",
    "min_sum_errors = [1.0 for i in range(a_dim)]\n",
    "min_sum_paramsG = copy.deepcopy(netG.state_dict())\n",
    "min_sum_paramsD = copy.deepcopy(netD.state_dict())\n",
    "\n",
    "# min_max_err = float('inf')\n",
    "# min_max_errors = [1.0 for i in range(a_dim)]\n",
    "# min_max_paramsG = copy.deepcopy(netG.state_dict())\n",
    "# min_max_paramsD = copy.deepcopy(netD.state_dict())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/15, iter: 0,\n",
      " errors: ['0.05891', '0.40264', '0.02776', '0.18810', '0.40710', '0.04202']\n",
      "Saved parameters\n",
      "epoch: 0/15, iter: 100,\n",
      " errors: ['0.03545', '0.34840', '0.05786', '0.16455', '0.43127', '0.03444']\n",
      "Saved parameters\n",
      "epoch: 0/15, iter: 200,\n",
      " errors: ['0.11171', '0.33866', '0.13599', '0.16647', '0.42639', '0.09630']\n",
      "epoch: 0/15, iter: 300,\n",
      " errors: ['0.13057', '0.34119', '0.11026', '0.18883', '0.44122', '0.13984']\n",
      "epoch: 0/15, iter: 400,\n",
      " errors: ['0.12433', '0.34987', '0.15813', '0.18647', '0.41546', '0.09783']\n",
      "epoch: 0/15, iter: 500,\n",
      " errors: ['0.12112', '0.35945', '0.10727', '0.19406', '0.42196', '0.09922']\n",
      "epoch: 0/15, iter: 600,\n",
      " errors: ['0.12191', '0.34968', '0.10475', '0.21655', '0.43706', '0.11088']\n",
      "epoch: 0/15, iter: 700,\n",
      " errors: ['0.10223', '0.34541', '0.10955', '0.18368', '0.42270', '0.10725']\n",
      "epoch: 0/15, iter: 800,\n",
      " errors: ['0.07061', '0.34116', '0.10192', '0.16770', '0.41853', '0.08501']\n",
      "epoch: 0/15, iter: 900,\n",
      " errors: ['0.06856', '0.35112', '0.09066', '0.17041', '0.41615', '0.06970']\n",
      "epoch: 0/15, iter: 1000,\n",
      " errors: ['0.07038', '0.35953', '0.07007', '0.16948', '0.40410', '0.06596']\n",
      "epoch: 0/15, iter: 1100,\n",
      " errors: ['0.07005', '0.35214', '0.06734', '0.16753', '0.41168', '0.07526']\n",
      "epoch: 0/15, iter: 1200,\n",
      " errors: ['0.06649', '0.34990', '0.06073', '0.16932', '0.41096', '0.06545']\n",
      "epoch: 0/15, iter: 1300,\n",
      " errors: ['0.07045', '0.35869', '0.05281', '0.16941', '0.40678', '0.08459']\n",
      "epoch: 0/15, iter: 1400,\n",
      " errors: ['0.06825', '0.36059', '0.05020', '0.18099', '0.39985', '0.11236']\n",
      "epoch: 0/15, iter: 1500,\n",
      " errors: ['0.07221', '0.37231', '0.06104', '0.18555', '0.39273', '0.12491']\n",
      "epoch: 0/15, iter: 1600,\n",
      " errors: ['0.06077', '0.37415', '0.07267', '0.19974', '0.39221', '0.14681']\n",
      "epoch: 0/15, iter: 1700,\n",
      " errors: ['0.06060', '0.38768', '0.08910', '0.20537', '0.38709', '0.15088']\n",
      "epoch: 0/15, iter: 1800,\n",
      " errors: ['0.05966', '0.40064', '0.10553', '0.18298', '0.39641', '0.15295']\n",
      "epoch: 0/15, iter: 1900,\n",
      " errors: ['0.04782', '0.40733', '0.11314', '0.18042', '0.40489', '0.16823']\n",
      "epoch: 0/15, iter: 2000,\n",
      " errors: ['0.05398', '0.40428', '0.10644', '0.17493', '0.40162', '0.17096']\n",
      "epoch: 1/15, iter: 2100,\n",
      " errors: ['0.07503', '0.40595', '0.12076', '0.20695', '0.40443', '0.18090']\n",
      "epoch: 1/15, iter: 2200,\n",
      " errors: ['0.10550', '0.40928', '0.12679', '0.22489', '0.40222', '0.17924']\n",
      "epoch: 1/15, iter: 2300,\n",
      " errors: ['0.13006', '0.40526', '0.13382', '0.23384', '0.40114', '0.18822']\n",
      "epoch: 1/15, iter: 2400,\n",
      " errors: ['0.14284', '0.40052', '0.13906', '0.24539', '0.38763', '0.19377']\n",
      "epoch: 1/15, iter: 2500,\n",
      " errors: ['0.14265', '0.40533', '0.13832', '0.23617', '0.37508', '0.18961']\n",
      "epoch: 1/15, iter: 2600,\n",
      " errors: ['0.14100', '0.40700', '0.13411', '0.23177', '0.38749', '0.18350']\n",
      "epoch: 1/15, iter: 2700,\n",
      " errors: ['0.14371', '0.40143', '0.12590', '0.21762', '0.40757', '0.17460']\n",
      "epoch: 1/15, iter: 2800,\n",
      " errors: ['0.12190', '0.39175', '0.12169', '0.21775', '0.40490', '0.17572']\n",
      "epoch: 1/15, iter: 2900,\n",
      " errors: ['0.09905', '0.41286', '0.11675', '0.22935', '0.40705', '0.16321']\n",
      "epoch: 1/15, iter: 3000,\n",
      " errors: ['0.12709', '0.40874', '0.11093', '0.21233', '0.39812', '0.14887']\n",
      "epoch: 1/15, iter: 3100,\n",
      " errors: ['0.11530', '0.40260', '0.12359', '0.21912', '0.38837', '0.15165']\n",
      "epoch: 1/15, iter: 3200,\n",
      " errors: ['0.13023', '0.40744', '0.11203', '0.23018', '0.40011', '0.16934']\n",
      "epoch: 1/15, iter: 3300,\n",
      " errors: ['0.11596', '0.39289', '0.11387', '0.22242', '0.40175', '0.16544']\n",
      "epoch: 1/15, iter: 3400,\n",
      " errors: ['0.12910', '0.40041', '0.11249', '0.23280', '0.40389', '0.15429']\n",
      "epoch: 1/15, iter: 3500,\n",
      " errors: ['0.10464', '0.39794', '0.12989', '0.22518', '0.40017', '0.15359']\n",
      "epoch: 1/15, iter: 3600,\n",
      " errors: ['0.12163', '0.40432', '0.12251', '0.20832', '0.39052', '0.14397']\n",
      "epoch: 1/15, iter: 3700,\n",
      " errors: ['0.11361', '0.40797', '0.11571', '0.23340', '0.39204', '0.15767']\n",
      "epoch: 1/15, iter: 3800,\n",
      " errors: ['0.13025', '0.39298', '0.11853', '0.22861', '0.39967', '0.16656']\n",
      "epoch: 1/15, iter: 3900,\n",
      " errors: ['0.12336', '0.41713', '0.12869', '0.23870', '0.39492', '0.16408']\n",
      "epoch: 1/15, iter: 4000,\n",
      " errors: ['0.14001', '0.40880', '0.13631', '0.24763', '0.39377', '0.19311']\n",
      "epoch: 2/15, iter: 4100,\n",
      " errors: ['0.15878', '0.41318', '0.14535', '0.23905', '0.39698', '0.19966']\n",
      "epoch: 2/15, iter: 4200,\n",
      " errors: ['0.14429', '0.39880', '0.14431', '0.25184', '0.39513', '0.20001']\n",
      "epoch: 2/15, iter: 4300,\n",
      " errors: ['0.15678', '0.40692', '0.15478', '0.24960', '0.40520', '0.20198']\n",
      "epoch: 2/15, iter: 4400,\n",
      " errors: ['0.13702', '0.39211', '0.13616', '0.25526', '0.39964', '0.19904']\n",
      "epoch: 2/15, iter: 4500,\n",
      " errors: ['0.15252', '0.39061', '0.12278', '0.24797', '0.40060', '0.20393']\n",
      "epoch: 2/15, iter: 4600,\n",
      " errors: ['0.13823', '0.39324', '0.13466', '0.23432', '0.38902', '0.19695']\n",
      "epoch: 2/15, iter: 4700,\n",
      " errors: ['0.13040', '0.39204', '0.12939', '0.23526', '0.39302', '0.19470']\n",
      "epoch: 2/15, iter: 4800,\n",
      " errors: ['0.13135', '0.38982', '0.12442', '0.23358', '0.39373', '0.19596']\n",
      "epoch: 2/15, iter: 4900,\n",
      " errors: ['0.12336', '0.39088', '0.11937', '0.22485', '0.39005', '0.19095']\n",
      "epoch: 2/15, iter: 5000,\n",
      " errors: ['0.11865', '0.37116', '0.12209', '0.22583', '0.39334', '0.17872']\n",
      "epoch: 2/15, iter: 5100,\n",
      " errors: ['0.11515', '0.37253', '0.11661', '0.21875', '0.38921', '0.17712']\n",
      "epoch: 2/15, iter: 5200,\n",
      " errors: ['0.10372', '0.38014', '0.11787', '0.21312', '0.38404', '0.17386']\n",
      "epoch: 2/15, iter: 5300,\n",
      " errors: ['0.08897', '0.36497', '0.10281', '0.20181', '0.38205', '0.16683']\n",
      "epoch: 2/15, iter: 5400,\n",
      " errors: ['0.10158', '0.36500', '0.09938', '0.20589', '0.39171', '0.14821']\n",
      "epoch: 2/15, iter: 5500,\n",
      " errors: ['0.08464', '0.35739', '0.09805', '0.19022', '0.37402', '0.14874']\n",
      "epoch: 2/15, iter: 5600,\n",
      " errors: ['0.08032', '0.35957', '0.08691', '0.17845', '0.39703', '0.12427']\n",
      "epoch: 2/15, iter: 5700,\n",
      " errors: ['0.08671', '0.35793', '0.08282', '0.18919', '0.36466', '0.12970']\n",
      "epoch: 2/15, iter: 5800,\n",
      " errors: ['0.07069', '0.35894', '0.08331', '0.18460', '0.39426', '0.13915']\n",
      "epoch: 2/15, iter: 5900,\n",
      " errors: ['0.07334', '0.35180', '0.07971', '0.18543', '0.37576', '0.12957']\n",
      "epoch: 2/15, iter: 6000,\n",
      " errors: ['0.07496', '0.35574', '0.08259', '0.17889', '0.38358', '0.12293']\n",
      "epoch: 2/15, iter: 6100,\n",
      " errors: ['0.08618', '0.36561', '0.07802', '0.18758', '0.39008', '0.11886']\n",
      "epoch: 3/15, iter: 6200,\n",
      " errors: ['0.09178', '0.35673', '0.08379', '0.18231', '0.38280', '0.11978']\n",
      "epoch: 3/15, iter: 6300,\n",
      " errors: ['0.08334', '0.35664', '0.07632', '0.16588', '0.38872', '0.12837']\n",
      "epoch: 3/15, iter: 6400,\n",
      " errors: ['0.09215', '0.36029', '0.07540', '0.19121', '0.38334', '0.12109']\n",
      "epoch: 3/15, iter: 6500,\n",
      " errors: ['0.09541', '0.35973', '0.07598', '0.18959', '0.37984', '0.11684']\n",
      "epoch: 3/15, iter: 6600,\n",
      " errors: ['0.09545', '0.34552', '0.07610', '0.18251', '0.37597', '0.11598']\n",
      "epoch: 3/15, iter: 6700,\n",
      " errors: ['0.09323', '0.34559', '0.07713', '0.18707', '0.37594', '0.12095']\n",
      "epoch: 3/15, iter: 6800,\n",
      " errors: ['0.09535', '0.35457', '0.06875', '0.18516', '0.38302', '0.12748']\n",
      "epoch: 3/15, iter: 6900,\n",
      " errors: ['0.09293', '0.36015', '0.06924', '0.16992', '0.38437', '0.11614']\n",
      "epoch: 3/15, iter: 7000,\n",
      " errors: ['0.10173', '0.35316', '0.07415', '0.17770', '0.38420', '0.11621']\n",
      "epoch: 3/15, iter: 7100,\n",
      " errors: ['0.09800', '0.34135', '0.08281', '0.18907', '0.38198', '0.11388']\n",
      "epoch: 3/15, iter: 7200,\n",
      " errors: ['0.09195', '0.35622', '0.07316', '0.19420', '0.39669', '0.11461']\n",
      "epoch: 3/15, iter: 7300,\n",
      " errors: ['0.08984', '0.34964', '0.08098', '0.17832', '0.38364', '0.11502']\n",
      "epoch: 3/15, iter: 7400,\n",
      " errors: ['0.10470', '0.34487', '0.07956', '0.18587', '0.36305', '0.10627']\n",
      "epoch: 3/15, iter: 7500,\n",
      " errors: ['0.08009', '0.34099', '0.06889', '0.17624', '0.36972', '0.10655']\n",
      "epoch: 3/15, iter: 7600,\n",
      " errors: ['0.10299', '0.34517', '0.07486', '0.17794', '0.35365', '0.11325']\n",
      "epoch: 3/15, iter: 7700,\n",
      " errors: ['0.09744', '0.35358', '0.06881', '0.19312', '0.37533', '0.11427']\n",
      "epoch: 3/15, iter: 7800,\n",
      " errors: ['0.09875', '0.32980', '0.08109', '0.19158', '0.38023', '0.11085']\n",
      "epoch: 3/15, iter: 7900,\n",
      " errors: ['0.09540', '0.33336', '0.07358', '0.18376', '0.37783', '0.10461']\n",
      "epoch: 3/15, iter: 8000,\n",
      " errors: ['0.10149', '0.35129', '0.07796', '0.17210', '0.39073', '0.11903']\n",
      "epoch: 3/15, iter: 8100,\n",
      " errors: ['0.10789', '0.36918', '0.07579', '0.17077', '0.38885', '0.11258']\n",
      "epoch: 4/15, iter: 8200,\n",
      " errors: ['0.11131', '0.35282', '0.08944', '0.18990', '0.37123', '0.10521']\n",
      "epoch: 4/15, iter: 8300,\n",
      " errors: ['0.10824', '0.34459', '0.08375', '0.18943', '0.37038', '0.12472']\n",
      "epoch: 4/15, iter: 8400,\n",
      " errors: ['0.09800', '0.34449', '0.06644', '0.17589', '0.36523', '0.13024']\n",
      "epoch: 4/15, iter: 8500,\n",
      " errors: ['0.10598', '0.34412', '0.08117', '0.16419', '0.37892', '0.13003']\n",
      "epoch: 4/15, iter: 8600,\n",
      " errors: ['0.11076', '0.34878', '0.09071', '0.18233', '0.37582', '0.13423']\n",
      "epoch: 4/15, iter: 8700,\n",
      " errors: ['0.10532', '0.34101', '0.07470', '0.18493', '0.36803', '0.12988']\n",
      "epoch: 4/15, iter: 8800,\n",
      " errors: ['0.10896', '0.34040', '0.09371', '0.17524', '0.37215', '0.12216']\n",
      "epoch: 4/15, iter: 8900,\n",
      " errors: ['0.10894', '0.35867', '0.09884', '0.18067', '0.36696', '0.13305']\n",
      "epoch: 4/15, iter: 9000,\n",
      " errors: ['0.10135', '0.35311', '0.09517', '0.18037', '0.36688', '0.13968']\n",
      "epoch: 4/15, iter: 9100,\n",
      " errors: ['0.09542', '0.34614', '0.09790', '0.17473', '0.37049', '0.13797']\n",
      "epoch: 4/15, iter: 9200,\n",
      " errors: ['0.10368', '0.31876', '0.10454', '0.19056', '0.37562', '0.12116']\n",
      "epoch: 4/15, iter: 9300,\n",
      " errors: ['0.10053', '0.35538', '0.09240', '0.19907', '0.37663', '0.13735']\n",
      "epoch: 4/15, iter: 9400,\n",
      " errors: ['0.09899', '0.35468', '0.08251', '0.17150', '0.37571', '0.12876']\n",
      "epoch: 4/15, iter: 9500,\n",
      " errors: ['0.11054', '0.35011', '0.09388', '0.19423', '0.37272', '0.12717']\n",
      "epoch: 4/15, iter: 9600,\n",
      " errors: ['0.11295', '0.35640', '0.09786', '0.18337', '0.38056', '0.12713']\n",
      "epoch: 4/15, iter: 9700,\n",
      " errors: ['0.11424', '0.34400', '0.09442', '0.17335', '0.37856', '0.12537']\n",
      "epoch: 4/15, iter: 9800,\n",
      " errors: ['0.11704', '0.34936', '0.09831', '0.17788', '0.35388', '0.12534']\n",
      "epoch: 4/15, iter: 9900,\n",
      " errors: ['0.10537', '0.35257', '0.07434', '0.17526', '0.39631', '0.13459']\n",
      "epoch: 4/15, iter: 10000,\n",
      " errors: ['0.10584', '0.33152', '0.09397', '0.19492', '0.37202', '0.12095']\n",
      "epoch: 4/15, iter: 10100,\n",
      " errors: ['0.10316', '0.35274', '0.10167', '0.17247', '0.36190', '0.11701']\n",
      "epoch: 4/15, iter: 10200,\n",
      " errors: ['0.11650', '0.34659', '0.09078', '0.18508', '0.37456', '0.12231']\n",
      "epoch: 5/15, iter: 10300,\n",
      " errors: ['0.09068', '0.35328', '0.09039', '0.15102', '0.38043', '0.11948']\n",
      "epoch: 5/15, iter: 10400,\n",
      " errors: ['0.11693', '0.33871', '0.09804', '0.18699', '0.37677', '0.13289']\n",
      "epoch: 5/15, iter: 10500,\n",
      " errors: ['0.10812', '0.34890', '0.09578', '0.16929', '0.35741', '0.13081']\n",
      "epoch: 5/15, iter: 10600,\n",
      " errors: ['0.11730', '0.34581', '0.08206', '0.18760', '0.37102', '0.11895']\n",
      "epoch: 5/15, iter: 10700,\n",
      " errors: ['0.11761', '0.33319', '0.08669', '0.19038', '0.36488', '0.12455']\n",
      "epoch: 5/15, iter: 10800,\n",
      " errors: ['0.11690', '0.36065', '0.08996', '0.18319', '0.37529', '0.13775']\n",
      "epoch: 5/15, iter: 10900,\n",
      " errors: ['0.10460', '0.33010', '0.09302', '0.19652', '0.37755', '0.13956']\n",
      "epoch: 5/15, iter: 11000,\n",
      " errors: ['0.10278', '0.35127', '0.08973', '0.18198', '0.38198', '0.13295']\n",
      "epoch: 5/15, iter: 11100,\n",
      " errors: ['0.10963', '0.34401', '0.09352', '0.17439', '0.35101', '0.11862']\n",
      "epoch: 5/15, iter: 11200,\n",
      " errors: ['0.11304', '0.34388', '0.08770', '0.17901', '0.38105', '0.14165']\n",
      "epoch: 5/15, iter: 11300,\n",
      " errors: ['0.10164', '0.33668', '0.09299', '0.19091', '0.37005', '0.13205']\n",
      "epoch: 5/15, iter: 11400,\n",
      " errors: ['0.08703', '0.35293', '0.09204', '0.18246', '0.37054', '0.13626']\n",
      "epoch: 5/15, iter: 11500,\n",
      " errors: ['0.10372', '0.32543', '0.09525', '0.19078', '0.36981', '0.13527']\n",
      "epoch: 5/15, iter: 11600,\n",
      " errors: ['0.11678', '0.33369', '0.08647', '0.19598', '0.36161', '0.14022']\n",
      "epoch: 5/15, iter: 11700,\n",
      " errors: ['0.10810', '0.33522', '0.09589', '0.18521', '0.35488', '0.13100']\n",
      "epoch: 5/15, iter: 11800,\n",
      " errors: ['0.11345', '0.35585', '0.08387', '0.20676', '0.36051', '0.12506']\n",
      "epoch: 5/15, iter: 11900,\n",
      " errors: ['0.10631', '0.32733', '0.09501', '0.18076', '0.36849', '0.13795']\n",
      "epoch: 5/15, iter: 12000,\n",
      " errors: ['0.09341', '0.36248', '0.10578', '0.19149', '0.36422', '0.14231']\n",
      "epoch: 5/15, iter: 12100,\n",
      " errors: ['0.11042', '0.31896', '0.09763', '0.17414', '0.36965', '0.13435']\n",
      "epoch: 5/15, iter: 12200,\n",
      " errors: ['0.10578', '0.35111', '0.08658', '0.19274', '0.35860', '0.12859']\n",
      "epoch: 6/15, iter: 12300,\n",
      " errors: ['0.11178', '0.34170', '0.09718', '0.18754', '0.38148', '0.14618']\n",
      "epoch: 6/15, iter: 12400,\n",
      " errors: ['0.10351', '0.33377', '0.08418', '0.17630', '0.35274', '0.13104']\n",
      "epoch: 6/15, iter: 12500,\n",
      " errors: ['0.10262', '0.33686', '0.09543', '0.17817', '0.38305', '0.12537']\n",
      "epoch: 6/15, iter: 12600,\n",
      " errors: ['0.12091', '0.33789', '0.08716', '0.17162', '0.36105', '0.12079']\n",
      "epoch: 6/15, iter: 12700,\n",
      " errors: ['0.10746', '0.33673', '0.09566', '0.19120', '0.37293', '0.12924']\n",
      "epoch: 6/15, iter: 12800,\n",
      " errors: ['0.09523', '0.31250', '0.08458', '0.19314', '0.34841', '0.14413']\n",
      "epoch: 6/15, iter: 12900,\n",
      " errors: ['0.09730', '0.34924', '0.08152', '0.18356', '0.38460', '0.14552']\n",
      "epoch: 6/15, iter: 13000,\n",
      " errors: ['0.10941', '0.31147', '0.09278', '0.19357', '0.36270', '0.12574']\n",
      "epoch: 6/15, iter: 13100,\n",
      " errors: ['0.09852', '0.35969', '0.09469', '0.18042', '0.35148', '0.13689']\n",
      "epoch: 6/15, iter: 13200,\n",
      " errors: ['0.08037', '0.32467', '0.09158', '0.17917', '0.35402', '0.14910']\n",
      "epoch: 6/15, iter: 13300,\n",
      " errors: ['0.10929', '0.35151', '0.09583', '0.19659', '0.36605', '0.13589']\n",
      "epoch: 6/15, iter: 13400,\n",
      " errors: ['0.11643', '0.34421', '0.09689', '0.19961', '0.36001', '0.13243']\n",
      "epoch: 6/15, iter: 13500,\n",
      " errors: ['0.11660', '0.34929', '0.09176', '0.18819', '0.37562', '0.14818']\n",
      "epoch: 6/15, iter: 13600,\n",
      " errors: ['0.10434', '0.34237', '0.09745', '0.19361', '0.36049', '0.14411']\n",
      "epoch: 6/15, iter: 13700,\n",
      " errors: ['0.10133', '0.34542', '0.09536', '0.17750', '0.37127', '0.14934']\n",
      "epoch: 6/15, iter: 13800,\n",
      " errors: ['0.11399', '0.33284', '0.09667', '0.17971', '0.37212', '0.14142']\n",
      "epoch: 6/15, iter: 13900,\n",
      " errors: ['0.11773', '0.35416', '0.08484', '0.19307', '0.36559', '0.12664']\n",
      "epoch: 6/15, iter: 14000,\n",
      " errors: ['0.11782', '0.33781', '0.07893', '0.17884', '0.35881', '0.12020']\n",
      "epoch: 6/15, iter: 14100,\n",
      " errors: ['0.12119', '0.32862', '0.08686', '0.20312', '0.35673', '0.13793']\n",
      "epoch: 6/15, iter: 14200,\n",
      " errors: ['0.10911', '0.34885', '0.08930', '0.18953', '0.36321', '0.13779']\n",
      "epoch: 6/15, iter: 14300,\n",
      " errors: ['0.11816', '0.34055', '0.08597', '0.20257', '0.36754', '0.12496']\n",
      "epoch: 7/15, iter: 14400,\n",
      " errors: ['0.10305', '0.33351', '0.08517', '0.18351', '0.38621', '0.12600']\n",
      "epoch: 7/15, iter: 14500,\n",
      " errors: ['0.11652', '0.33500', '0.09688', '0.20318', '0.36080', '0.13562']\n",
      "epoch: 7/15, iter: 14600,\n",
      " errors: ['0.10629', '0.34629', '0.10007', '0.19613', '0.36696', '0.12590']\n",
      "epoch: 7/15, iter: 14700,\n",
      " errors: ['0.11569', '0.31799', '0.09609', '0.19484', '0.37981', '0.13779']\n",
      "epoch: 7/15, iter: 14800,\n",
      " errors: ['0.11362', '0.32994', '0.09942', '0.19838', '0.36680', '0.13706']\n",
      "epoch: 7/15, iter: 14900,\n",
      " errors: ['0.11092', '0.35392', '0.08106', '0.18470', '0.36482', '0.14137']\n",
      "epoch: 7/15, iter: 15000,\n",
      " errors: ['0.11475', '0.32671', '0.09855', '0.19519', '0.36574', '0.14238']\n",
      "epoch: 7/15, iter: 15100,\n",
      " errors: ['0.10679', '0.33373', '0.09731', '0.19232', '0.35473', '0.15088']\n",
      "epoch: 7/15, iter: 15200,\n",
      " errors: ['0.10894', '0.34630', '0.10885', '0.18824', '0.36255', '0.15291']\n",
      "epoch: 7/15, iter: 15300,\n",
      " errors: ['0.09737', '0.32808', '0.10280', '0.17413', '0.36150', '0.14999']\n",
      "epoch: 7/15, iter: 15400,\n",
      " errors: ['0.10716', '0.35397', '0.10071', '0.20140', '0.36395', '0.14148']\n",
      "epoch: 7/15, iter: 15500,\n",
      " errors: ['0.08961', '0.34155', '0.09550', '0.18749', '0.36958', '0.13784']\n",
      "epoch: 7/15, iter: 15600,\n",
      " errors: ['0.09937', '0.34122', '0.09302', '0.18316', '0.37279', '0.13248']\n",
      "epoch: 7/15, iter: 15700,\n",
      " errors: ['0.11682', '0.34073', '0.10025', '0.19943', '0.36108', '0.14313']\n",
      "epoch: 7/15, iter: 15800,\n",
      " errors: ['0.10850', '0.34104', '0.09526', '0.18612', '0.34842', '0.13760']\n",
      "epoch: 7/15, iter: 15900,\n",
      " errors: ['0.10920', '0.34350', '0.09193', '0.18596', '0.37466', '0.12747']\n",
      "epoch: 7/15, iter: 16000,\n",
      " errors: ['0.11433', '0.31847', '0.08988', '0.18629', '0.36085', '0.12732']\n",
      "epoch: 7/15, iter: 16100,\n",
      " errors: ['0.11119', '0.34123', '0.09441', '0.18071', '0.35116', '0.12878']\n",
      "epoch: 7/15, iter: 16200,\n",
      " errors: ['0.11177', '0.32955', '0.09417', '0.18989', '0.37547', '0.12406']\n",
      "epoch: 7/15, iter: 16300,\n",
      " errors: ['0.11636', '0.33487', '0.09601', '0.18256', '0.35858', '0.12086']\n",
      "epoch: 8/15, iter: 16400,\n",
      " errors: ['0.11774', '0.34477', '0.09613', '0.19241', '0.35182', '0.13047']\n",
      "epoch: 8/15, iter: 16500,\n",
      " errors: ['0.10314', '0.30237', '0.08876', '0.17769', '0.35393', '0.13558']\n",
      "epoch: 8/15, iter: 16600,\n",
      " errors: ['0.11254', '0.34621', '0.10077', '0.17582', '0.37117', '0.12983']\n",
      "epoch: 8/15, iter: 16700,\n",
      " errors: ['0.11048', '0.31490', '0.09770', '0.18329', '0.35341', '0.14332']\n",
      "epoch: 8/15, iter: 16800,\n",
      " errors: ['0.11893', '0.33356', '0.09850', '0.17869', '0.36435', '0.12620']\n",
      "epoch: 8/15, iter: 16900,\n",
      " errors: ['0.12177', '0.34256', '0.10818', '0.19842', '0.36252', '0.12500']\n",
      "epoch: 8/15, iter: 17000,\n",
      " errors: ['0.12172', '0.32541', '0.10265', '0.18016', '0.37439', '0.12991']\n",
      "epoch: 8/15, iter: 17100,\n",
      " errors: ['0.11036', '0.33658', '0.09941', '0.18477', '0.33197', '0.13043']\n",
      "epoch: 8/15, iter: 17200,\n",
      " errors: ['0.10246', '0.32696', '0.07309', '0.18548', '0.36990', '0.12841']\n",
      "epoch: 8/15, iter: 17300,\n",
      " errors: ['0.10724', '0.32857', '0.09588', '0.19210', '0.35834', '0.10612']\n",
      "epoch: 8/15, iter: 17400,\n",
      " errors: ['0.10661', '0.32470', '0.09757', '0.18629', '0.36082', '0.13485']\n",
      "epoch: 8/15, iter: 17500,\n",
      " errors: ['0.11276', '0.34345', '0.10189', '0.18620', '0.35855', '0.13183']\n",
      "epoch: 8/15, iter: 17600,\n",
      " errors: ['0.11729', '0.33751', '0.09829', '0.18039', '0.36356', '0.13667']\n",
      "epoch: 8/15, iter: 17700,\n",
      " errors: ['0.11309', '0.33763', '0.09834', '0.18181', '0.36722', '0.12387']\n",
      "epoch: 8/15, iter: 17800,\n",
      " errors: ['0.12018', '0.33386', '0.08473', '0.19856', '0.34906', '0.14586']\n",
      "epoch: 8/15, iter: 17900,\n",
      " errors: ['0.10857', '0.30149', '0.09432', '0.17406', '0.37565', '0.15139']\n",
      "epoch: 8/15, iter: 18000,\n",
      " errors: ['0.09699', '0.33936', '0.09549', '0.18146', '0.33443', '0.14653']\n",
      "epoch: 8/15, iter: 18100,\n",
      " errors: ['0.10180', '0.33172', '0.08852', '0.19361', '0.35027', '0.14790']\n",
      "epoch: 8/15, iter: 18200,\n",
      " errors: ['0.12430', '0.32375', '0.08785', '0.18505', '0.34549', '0.14150']\n",
      "epoch: 8/15, iter: 18300,\n",
      " errors: ['0.10982', '0.33340', '0.09561', '0.19250', '0.35972', '0.14060']\n",
      "epoch: 8/15, iter: 18400,\n",
      " errors: ['0.11876', '0.32739', '0.09732', '0.18175', '0.37325', '0.12386']\n",
      "epoch: 9/15, iter: 18500,\n",
      " errors: ['0.10749', '0.33347', '0.10694', '0.17222', '0.36686', '0.13015']\n",
      "epoch: 9/15, iter: 18600,\n",
      " errors: ['0.11666', '0.32474', '0.10727', '0.17714', '0.36008', '0.13540']\n",
      "epoch: 9/15, iter: 18700,\n",
      " errors: ['0.11090', '0.34378', '0.10524', '0.18701', '0.35023', '0.14629']\n",
      "epoch: 9/15, iter: 18800,\n",
      " errors: ['0.11569', '0.31350', '0.09661', '0.19128', '0.36257', '0.14921']\n",
      "epoch: 9/15, iter: 18900,\n",
      " errors: ['0.11371', '0.32107', '0.09816', '0.19407', '0.34864', '0.14635']\n",
      "epoch: 9/15, iter: 19000,\n",
      " errors: ['0.10330', '0.34187', '0.09890', '0.20120', '0.36980', '0.15039']\n",
      "epoch: 9/15, iter: 19100,\n",
      " errors: ['0.10527', '0.31481', '0.10329', '0.18215', '0.34907', '0.13811']\n",
      "epoch: 9/15, iter: 19200,\n",
      " errors: ['0.10627', '0.31625', '0.10314', '0.18359', '0.34583', '0.12616']\n",
      "epoch: 9/15, iter: 19300,\n",
      " errors: ['0.10295', '0.33646', '0.10059', '0.18807', '0.36753', '0.11791']\n",
      "epoch: 9/15, iter: 19400,\n",
      " errors: ['0.11033', '0.30777', '0.08690', '0.18888', '0.34525', '0.12623']\n",
      "epoch: 9/15, iter: 19500,\n",
      " errors: ['0.11879', '0.31516', '0.09511', '0.19837', '0.35005', '0.12982']\n",
      "epoch: 9/15, iter: 19600,\n",
      " errors: ['0.11420', '0.32528', '0.08505', '0.17696', '0.35709', '0.13197']\n",
      "epoch: 9/15, iter: 19700,\n",
      " errors: ['0.11482', '0.31716', '0.07845', '0.18250', '0.35918', '0.13358']\n",
      "epoch: 9/15, iter: 19800,\n",
      " errors: ['0.11782', '0.31139', '0.07705', '0.20192', '0.35107', '0.13620']\n",
      "epoch: 9/15, iter: 19900,\n",
      " errors: ['0.12214', '0.32417', '0.09490', '0.17802', '0.35736', '0.10547']\n",
      "epoch: 9/15, iter: 20000,\n",
      " errors: ['0.12136', '0.31496', '0.07981', '0.18477', '0.36442', '0.12247']\n",
      "epoch: 9/15, iter: 20100,\n",
      " errors: ['0.12453', '0.32008', '0.09605', '0.16952', '0.34379', '0.11443']\n",
      "epoch: 9/15, iter: 20200,\n",
      " errors: ['0.10780', '0.32004', '0.08468', '0.17967', '0.37934', '0.11314']\n",
      "epoch: 9/15, iter: 20300,\n",
      " errors: ['0.11322', '0.29637', '0.07908', '0.17744', '0.35437', '0.11471']\n",
      "epoch: 9/15, iter: 20400,\n",
      " errors: ['0.11563', '0.33071', '0.08361', '0.17408', '0.36628', '0.12064']\n",
      "epoch: 10/15, iter: 20500,\n",
      " errors: ['0.12318', '0.32044', '0.09609', '0.17011', '0.35736', '0.11744']\n",
      "epoch: 10/15, iter: 20600,\n",
      " errors: ['0.10060', '0.30232', '0.09283', '0.17293', '0.35867', '0.12065']\n",
      "epoch: 10/15, iter: 20700,\n",
      " errors: ['0.10171', '0.31996', '0.08475', '0.16931', '0.35436', '0.11907']\n",
      "epoch: 10/15, iter: 20800,\n",
      " errors: ['0.12744', '0.28694', '0.08260', '0.16474', '0.35506', '0.12156']\n",
      "epoch: 10/15, iter: 20900,\n",
      " errors: ['0.12686', '0.30778', '0.08840', '0.17517', '0.35750', '0.11654']\n",
      "epoch: 10/15, iter: 21000,\n",
      " errors: ['0.12029', '0.30250', '0.10010', '0.17217', '0.33968', '0.14042']\n",
      "epoch: 10/15, iter: 21100,\n",
      " errors: ['0.11041', '0.30327', '0.10186', '0.17716', '0.35391', '0.13202']\n",
      "epoch: 10/15, iter: 21200,\n",
      " errors: ['0.10924', '0.30398', '0.09644', '0.16657', '0.34822', '0.12867']\n",
      "epoch: 10/15, iter: 21300,\n",
      " errors: ['0.11719', '0.30329', '0.10421', '0.15189', '0.33664', '0.13354']\n",
      "epoch: 10/15, iter: 21400,\n",
      " errors: ['0.11889', '0.31381', '0.09895', '0.15886', '0.34804', '0.12398']\n",
      "epoch: 10/15, iter: 21500,\n",
      " errors: ['0.11979', '0.29629', '0.10008', '0.16984', '0.33830', '0.13028']\n",
      "epoch: 10/15, iter: 21600,\n",
      " errors: ['0.12022', '0.30826', '0.09711', '0.17510', '0.34876', '0.12851']\n",
      "epoch: 10/15, iter: 21700,\n",
      " errors: ['0.11953', '0.32032', '0.09654', '0.16584', '0.34427', '0.12540']\n",
      "epoch: 10/15, iter: 21800,\n",
      " errors: ['0.11816', '0.31325', '0.07710', '0.17967', '0.34309', '0.12649']\n",
      "epoch: 10/15, iter: 21900,\n",
      " errors: ['0.11322', '0.29741', '0.08058', '0.17604', '0.33883', '0.13824']\n",
      "epoch: 10/15, iter: 22000,\n",
      " errors: ['0.11192', '0.31569', '0.08018', '0.16726', '0.34096', '0.12287']\n",
      "epoch: 10/15, iter: 22100,\n",
      " errors: ['0.11952', '0.31150', '0.09530', '0.15051', '0.34116', '0.12855']\n",
      "epoch: 10/15, iter: 22200,\n",
      " errors: ['0.09222', '0.29475', '0.08450', '0.16765', '0.35105', '0.12983']\n",
      "epoch: 10/15, iter: 22300,\n",
      " errors: ['0.09392', '0.29025', '0.08202', '0.16247', '0.34501', '0.12340']\n",
      "epoch: 10/15, iter: 22400,\n",
      " errors: ['0.11166', '0.31799', '0.08519', '0.15510', '0.34246', '0.11125']\n",
      "epoch: 10/15, iter: 22500,\n",
      " errors: ['0.12867', '0.30550', '0.09282', '0.17129', '0.36746', '0.10836']\n",
      "epoch: 11/15, iter: 22600,\n",
      " errors: ['0.11296', '0.31668', '0.08641', '0.17644', '0.34126', '0.11608']\n",
      "epoch: 11/15, iter: 22700,\n",
      " errors: ['0.08429', '0.31561', '0.09076', '0.17112', '0.36114', '0.13052']\n",
      "epoch: 11/15, iter: 22800,\n",
      " errors: ['0.10471', '0.28904', '0.08646', '0.18026', '0.33719', '0.13024']\n",
      "epoch: 11/15, iter: 22900,\n",
      " errors: ['0.11779', '0.31655', '0.09550', '0.18347', '0.34390', '0.13964']\n",
      "epoch: 11/15, iter: 23000,\n",
      " errors: ['0.11961', '0.32201', '0.10021', '0.18038', '0.34718', '0.12669']\n",
      "epoch: 11/15, iter: 23100,\n",
      " errors: ['0.10881', '0.32889', '0.11239', '0.16226', '0.34144', '0.11167']\n",
      "epoch: 11/15, iter: 23200,\n",
      " errors: ['0.10820', '0.31391', '0.10405', '0.15987', '0.34551', '0.12164']\n",
      "epoch: 11/15, iter: 23300,\n",
      " errors: ['0.08852', '0.32640', '0.08410', '0.16421', '0.34032', '0.13143']\n",
      "epoch: 11/15, iter: 23400,\n",
      " errors: ['0.10409', '0.32991', '0.09928', '0.15503', '0.34444', '0.13543']\n",
      "epoch: 11/15, iter: 23500,\n",
      " errors: ['0.11053', '0.30981', '0.09590', '0.15400', '0.33455', '0.12957']\n",
      "epoch: 11/15, iter: 23600,\n",
      " errors: ['0.11425', '0.30391', '0.10640', '0.14781', '0.33148', '0.11223']\n",
      "epoch: 11/15, iter: 23700,\n",
      " errors: ['0.11267', '0.33238', '0.11735', '0.16962', '0.34948', '0.12484']\n",
      "epoch: 11/15, iter: 23800,\n",
      " errors: ['0.09923', '0.28623', '0.11895', '0.16140', '0.35026', '0.12224']\n",
      "epoch: 11/15, iter: 23900,\n",
      " errors: ['0.10744', '0.31879', '0.10259', '0.16283', '0.32538', '0.11961']\n",
      "epoch: 11/15, iter: 24000,\n",
      " errors: ['0.09354', '0.29768', '0.09317', '0.16863', '0.33923', '0.12329']\n",
      "epoch: 11/15, iter: 24100,\n",
      " errors: ['0.08971', '0.33479', '0.08375', '0.16646', '0.33092', '0.12572']\n",
      "epoch: 11/15, iter: 24200,\n",
      " errors: ['0.11193', '0.30578', '0.09871', '0.15879', '0.33657', '0.12516']\n",
      "epoch: 11/15, iter: 24300,\n",
      " errors: ['0.11280', '0.32377', '0.10695', '0.15643', '0.33907', '0.11819']\n",
      "epoch: 11/15, iter: 24400,\n",
      " errors: ['0.11773', '0.33464', '0.10731', '0.15642', '0.33633', '0.12413']\n",
      "epoch: 11/15, iter: 24500,\n",
      " errors: ['0.11677', '0.30432', '0.09551', '0.15454', '0.33734', '0.13008']\n",
      "epoch: 12/15, iter: 24600,\n",
      " errors: ['0.08879', '0.31195', '0.09340', '0.14091', '0.33002', '0.12001']\n",
      "epoch: 12/15, iter: 24700,\n",
      " errors: ['0.08824', '0.31502', '0.09844', '0.14369', '0.32837', '0.12731']\n",
      "epoch: 12/15, iter: 24800,\n",
      " errors: ['0.07720', '0.30111', '0.08297', '0.14427', '0.33508', '0.09792']\n",
      "Saved parameters\n",
      "epoch: 12/15, iter: 24900,\n",
      " errors: ['0.08407', '0.31485', '0.09344', '0.15565', '0.33313', '0.13381']\n",
      "epoch: 12/15, iter: 25000,\n",
      " errors: ['0.09953', '0.30567', '0.06887', '0.15909', '0.31255', '0.13551']\n",
      "epoch: 12/15, iter: 25100,\n",
      " errors: ['0.08239', '0.30415', '0.07425', '0.16016', '0.31709', '0.12911']\n",
      "epoch: 12/15, iter: 25200,\n",
      " errors: ['0.07741', '0.30921', '0.10049', '0.15037', '0.32661', '0.13661']\n",
      "epoch: 12/15, iter: 25300,\n",
      " errors: ['0.08812', '0.30834', '0.08151', '0.15029', '0.32075', '0.13572']\n",
      "epoch: 12/15, iter: 25400,\n",
      " errors: ['0.09815', '0.30635', '0.08667', '0.16790', '0.31843', '0.13207']\n",
      "epoch: 12/15, iter: 25500,\n",
      " errors: ['0.11577', '0.29980', '0.09520', '0.16652', '0.33609', '0.13531']\n",
      "epoch: 12/15, iter: 25600,\n",
      " errors: ['0.11548', '0.28614', '0.11542', '0.17199', '0.32986', '0.12604']\n",
      "epoch: 12/15, iter: 25700,\n",
      " errors: ['0.11053', '0.31455', '0.08989', '0.17789', '0.33246', '0.14362']\n",
      "epoch: 12/15, iter: 25800,\n",
      " errors: ['0.09122', '0.30197', '0.08102', '0.15666', '0.35217', '0.13746']\n",
      "epoch: 12/15, iter: 25900,\n",
      " errors: ['0.09291', '0.29255', '0.09585', '0.15794', '0.33796', '0.14488']\n",
      "epoch: 12/15, iter: 26000,\n",
      " errors: ['0.10431', '0.31507', '0.10848', '0.16693', '0.34895', '0.13857']\n",
      "epoch: 12/15, iter: 26100,\n",
      " errors: ['0.11007', '0.31978', '0.11030', '0.16517', '0.33545', '0.13090']\n",
      "epoch: 12/15, iter: 26200,\n",
      " errors: ['0.11145', '0.31855', '0.10755', '0.15889', '0.32523', '0.14309']\n",
      "epoch: 12/15, iter: 26300,\n",
      " errors: ['0.11882', '0.30915', '0.10763', '0.16548', '0.33494', '0.14481']\n",
      "epoch: 12/15, iter: 26400,\n",
      " errors: ['0.11313', '0.30357', '0.11013', '0.16788', '0.34569', '0.13587']\n",
      "epoch: 12/15, iter: 26500,\n",
      " errors: ['0.10475', '0.31218', '0.09487', '0.17954', '0.34080', '0.13990']\n",
      "epoch: 12/15, iter: 26600,\n",
      " errors: ['0.11790', '0.30605', '0.09782', '0.16810', '0.33329', '0.13625']\n",
      "epoch: 13/15, iter: 26700,\n",
      " errors: ['0.11821', '0.31466', '0.11018', '0.16829', '0.35961', '0.13746']\n",
      "epoch: 13/15, iter: 26800,\n",
      " errors: ['0.10336', '0.31016', '0.11988', '0.15601', '0.32711', '0.14633']\n",
      "epoch: 13/15, iter: 26900,\n",
      " errors: ['0.09963', '0.31351', '0.11567', '0.15745', '0.33340', '0.14289']\n",
      "epoch: 13/15, iter: 27000,\n",
      " errors: ['0.09084', '0.29587', '0.10445', '0.17292', '0.35069', '0.15068']\n",
      "epoch: 13/15, iter: 27100,\n",
      " errors: ['0.11114', '0.30215', '0.10304', '0.16951', '0.31171', '0.14572']\n",
      "epoch: 13/15, iter: 27200,\n",
      " errors: ['0.10549', '0.30984', '0.09084', '0.16938', '0.33518', '0.13564']\n",
      "epoch: 13/15, iter: 27300,\n",
      " errors: ['0.09132', '0.30635', '0.09200', '0.17289', '0.32387', '0.13301']\n",
      "epoch: 13/15, iter: 27400,\n",
      " errors: ['0.09824', '0.31804', '0.10317', '0.17613', '0.32027', '0.12505']\n",
      "epoch: 13/15, iter: 27500,\n",
      " errors: ['0.11247', '0.31686', '0.10050', '0.16091', '0.31733', '0.12705']\n",
      "epoch: 13/15, iter: 27600,\n",
      " errors: ['0.10806', '0.30221', '0.10569', '0.17286', '0.31575', '0.13364']\n",
      "epoch: 13/15, iter: 27700,\n",
      " errors: ['0.09946', '0.30874', '0.09519', '0.15904', '0.33224', '0.14147']\n",
      "epoch: 13/15, iter: 27800,\n",
      " errors: ['0.09223', '0.31201', '0.10251', '0.17981', '0.33776', '0.14603']\n",
      "epoch: 13/15, iter: 27900,\n",
      " errors: ['0.10713', '0.32007', '0.10191', '0.16800', '0.32273', '0.13046']\n",
      "epoch: 13/15, iter: 28000,\n",
      " errors: ['0.10336', '0.29502', '0.10409', '0.17016', '0.32745', '0.13359']\n",
      "epoch: 13/15, iter: 28100,\n",
      " errors: ['0.09418', '0.30906', '0.11700', '0.16548', '0.34093', '0.13371']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     32\u001B[0m lossDf\u001B[38;5;241m.\u001B[39mbackward(mone)\n\u001B[1;32m     33\u001B[0m lossD \u001B[38;5;241m=\u001B[39m lossDr \u001B[38;5;241m-\u001B[39m lossDf\n\u001B[0;32m---> 34\u001B[0m \u001B[43moptD\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# train Generator with probability 1/5\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m iters\u001B[38;5;241m%\u001B[39m\u001B[38;5;241m5\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/optim/optimizer.py:113\u001B[0m, in \u001B[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    111\u001B[0m profile_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimizer.step#\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.step\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(obj\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mrecord_function(profile_name):\n\u001B[0;32m--> 113\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001B[0m, in \u001B[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclone():\n\u001B[0;32m---> 27\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/optim/rmsprop.py:141\u001B[0m, in \u001B[0;36mRMSprop.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    136\u001B[0m             grad_avgs\u001B[38;5;241m.\u001B[39mappend(state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrad_avg\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    138\u001B[0m         state[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 141\u001B[0m     \u001B[43mrmsprop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m            \u001B[49m\u001B[43msquare_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m            \u001B[49m\u001B[43mgrad_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmomentum_buffer_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m            \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43malpha\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[43m            \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m            \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmomentum\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcentered\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcentered\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m            \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/optim/rmsprop.py:188\u001B[0m, in \u001B[0;36mrmsprop\u001B[0;34m(params, grads, square_avgs, grad_avgs, momentum_buffer_list, foreach, lr, alpha, eps, weight_decay, momentum, centered)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    186\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_rmsprop\n\u001B[0;32m--> 188\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m     \u001B[49m\u001B[43msquare_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    192\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmomentum_buffer_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    194\u001B[0m \u001B[43m     \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    195\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    196\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmomentum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    198\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcentered\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcentered\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/GAN/lib/python3.10/site-packages/torch/optim/rmsprop.py:221\u001B[0m, in \u001B[0;36m_single_tensor_rmsprop\u001B[0;34m(params, grads, square_avgs, grad_avgs, momentum_buffer_list, lr, alpha, eps, weight_decay, momentum, centered)\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weight_decay \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    219\u001B[0m     grad \u001B[38;5;241m=\u001B[39m grad\u001B[38;5;241m.\u001B[39madd(param, alpha\u001B[38;5;241m=\u001B[39mweight_decay)\n\u001B[0;32m--> 221\u001B[0m \u001B[43msquare_avg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmul_\u001B[49m\u001B[43m(\u001B[49m\u001B[43malpha\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maddcmul_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m centered:\n\u001B[1;32m    224\u001B[0m     grad_avg \u001B[38;5;241m=\u001B[39m grad_avgs[i]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        netD.zero_grad()\n",
    "\n",
    "        # weight clipping so critic is lipschitz\n",
    "        for p in netD.parameters():\n",
    "            p.data.clamp_(-weight_cliping_limit, weight_cliping_limit)\n",
    "\n",
    "        # check actual batch size (last batch could be shorter)\n",
    "        b_size = data.size(0)\n",
    "\n",
    "        # Train Discriminator\n",
    "        # first on real data\n",
    "        out_D_real = netD(data)\n",
    "        lossDr = out_D_real.mean(0).view(1)\n",
    "        lossDr.backward(one)\n",
    "\n",
    "        # then on fake data\n",
    "\n",
    "        # data has shape (b_size, w_dim + a_dim) where w_dim are the dimensions of the driving BM and a_dim is the dim of Levy Areas\n",
    "        W = data[:,:w_dim]\n",
    "        A_real = data[:,w_dim:(w_dim + a_dim)]\n",
    "        noise = torch.randn((b_size,noise_size), dtype=torch.float, device=device)\n",
    "        gen_in = torch.cat((noise,W),1)\n",
    "        # generate fake data\n",
    "        generated_A = netG(gen_in)\n",
    "        fake_in = torch.cat((W,generated_A.detach()),1)\n",
    "\n",
    "        lossDf = netD(fake_in)\n",
    "        lossDf = lossDf.mean(0).view(1)\n",
    "        lossDf.backward(mone)\n",
    "        lossD = lossDr - lossDf\n",
    "        optD.step()\n",
    "\n",
    "        # train Generator with probability 1/5\n",
    "        if iters%5 == 0:\n",
    "            netG.zero_grad()\n",
    "\n",
    "            fake_in = torch.cat((W,generated_A),1)\n",
    "            lossG = netD(fake_in)\n",
    "            lossG = lossG.mean(0).view(1)\n",
    "            lossG.backward(one)\n",
    "            optG.step()\n",
    "\n",
    "        if iters%100 == 0:\n",
    "            # Test Wasserstein error for fixed W\n",
    "            noise = torch.randn((test_batch_size,noise_size), dtype=torch.float, device=device)\n",
    "            g_in = torch.cat((noise,W_fixed),1)\n",
    "            A_fixed_gen = netG(g_in).detach().numpy()\n",
    "            errors = [sqrt(ot.wasserstein_1d(A_fixed_true[:,i],A_fixed_gen[:,i],p=2)) for i in range(a_dim)]\n",
    "\n",
    "            # Test Chen discrepancy\n",
    "            # W = torch.randn((4*batch_size, w_dim), dtype= torch.float, device=device)\n",
    "            # noise = torch.randn((4*batch_size,noise_size), dtype=torch.float, device=device)\n",
    "            # gen_in = torch.cat((noise,W),1)\n",
    "            # A_gen = netG(gen_in)\n",
    "            # w_a = torch.cat((W,A_gen.detach()),1)\n",
    "            # ch_err = chen_error_2step(w_a)\n",
    "\n",
    "            # Print out partial results\n",
    "            pretty_errors = [\"{0:0.5f}\".format(i) for i in errors]\n",
    "            # pretty_chen_errors = [\"{0:0.5f}\".format(i) for i in ch_err]\n",
    "            print(f\"epoch: {epoch}/{num_epochs}, iter: {iters},\\n errors: {pretty_errors}\")\n",
    "            # Save for plotting\n",
    "            wass_errors.append(errors)\n",
    "            # chen_errors.append(ch_err)\n",
    "\n",
    "            # Early stopping checkpoint\n",
    "            error_sum = sum(errors)\n",
    "            if error_sum <= min_sum:\n",
    "                min_sum = error_sum\n",
    "                min_sum_errors = errors\n",
    "                min_sum_paramsG = copy.deepcopy(netG.state_dict())\n",
    "                min_sum_paramsD = copy.deepcopy(netD.state_dict())\n",
    "                print(\"Saved parameters\")\n",
    "\n",
    "        iters += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "W_fixed = [1.0,-0.5,-1.2,-0.3,0.7,0.2,-0.9,0.1,1.7]\n",
    "list_pairs(5) = [(1, 2), (1, 3), (1, 4), (1, 5), (2, 3), (2, 4), (2, 5), (3, 4), (3, 5), (4, 5)]\n",
    "\n",
    "GAN2 best: ['0.06348', '0.25953', '0.06187', '0.11594', '0.12005', '0.11992', '0.07918', '0.15956', '0.16242', '0.01383']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Return to early stopping checkpoint\n",
    "if which_model == 1:\n",
    "    best_netG = Generator1().to(device)\n",
    "elif which_model == 2:\n",
    "    best_netG = Generator2().to(device)\n",
    "\n",
    "best_netG.load_state_dict(min_sum_paramsG)\n",
    "\n",
    "torch.save(min_sum_paramsG, f'model_saves/GAN2_{w_dim}d_24epochs_generator.pt')\n",
    "torch.save(min_sum_paramsD, f'model_saves/GAN2_{w_dim}d_24epochs_discriminator.pt')\n",
    "# best_netD = Discriminator()\n",
    "# best_netD.load_state_dict(min_sum_paramsD)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test Wasserstein error for fixed W\n",
    "noise = torch.randn((test_batch_size,noise_size), dtype=torch.float, device=device)\n",
    "g_in = torch.cat((noise,W_fixed),1)\n",
    "A_fixed_gen = best_netG(g_in).detach().numpy()\n",
    "errors = [sqrt(ot.wasserstein_1d(A_fixed_true[:,i],A_fixed_gen[:,i],p=2)) for i in range(a_dim)]\n",
    "\n",
    "# Print out partial results\n",
    "pretty_errors = [\"{0:0.5f}\".format(i) for i in errors]\n",
    "print(f\"best net errors: {pretty_errors}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "best net errors: ['0.06348', '0.25953', '0.06187', '0.11594', '0.12005', '0.11992', '0.07918', '0.15956', '0.16242', '0.01383']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Draw errors through iterations\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"2-Wasserstein distance of generated samples from the original samples for fixed W increment\")\n",
    "plt.plot(wass_errors)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Wasserstein distance\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"2-Wasserstein distances after 2-step Chen recombinations\")\n",
    "plt.plot(chen_errors)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"2-Wasserstein distance\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chen_iters = 0\n",
    "chen_training_wass_errors = []\n",
    "chen_training_chen_errors = []\n",
    "for i in range(num_Chen_iters):\n",
    "    netD.zero_grad()\n",
    "\n",
    "    # weight clipping so critic is lipschitz\n",
    "    for p in netD.parameters():\n",
    "        p.data.clamp_(-weight_cliping_limit, weight_cliping_limit)\n",
    "\n",
    "    # Train Discriminator\n",
    "    # generate 4*batch_size of fake data\n",
    "    W = torch.randn((4*batch_size, w_dim), dtype= torch.float, device=device)\n",
    "    noise = torch.randn((4*batch_size,noise_size), dtype=torch.float, device=device)\n",
    "    gen_in = torch.cat((noise,W),1)\n",
    "    A_gen = netG(gen_in)\n",
    "    fake_in = torch.cat((W,A_gen.detach()),1)\n",
    "    lossD_fake = netD(fake_in)\n",
    "    lossD_fake = lossD_fake.mean(0).view(1)\n",
    "    lossD_fake.backward(mone)\n",
    "\n",
    "    # now use chen_combine to produce \"true\" data from the fake one\n",
    "    # using chen_combine twice reduces batch dimension from 4*batch_size to batch_size\n",
    "    true_data = chen_combine(fake_in.detach())\n",
    "    true_data = chen_combine(true_data)\n",
    "    true_data = chen_combine(true_data)\n",
    "    assert true_data.size(0) == batch_size//2\n",
    "\n",
    "    lossD_real = netD(true_data)\n",
    "    lossD_real = 8 * lossD_real.mean(0).view(1) # multiply by 4 to counteract the 4x smaller batch\n",
    "    lossD_real.backward(one)\n",
    "    optD.step()\n",
    "\n",
    "    # train Generator with probability 1/5\n",
    "    # if np.random.randint(1,6) == 5:\n",
    "    if True:\n",
    "        netG.zero_grad()\n",
    "\n",
    "        fake_in = torch.cat((W,A_gen),1)\n",
    "        lossG = netD(fake_in)\n",
    "        lossG = lossG.mean(0).view(1)\n",
    "        lossG.backward(one)\n",
    "        optG.step()\n",
    "\n",
    "    if chen_iters%100 == 0:\n",
    "        # Test Wasserstein error for fixed W\n",
    "        noise = torch.randn((test_batch_size,noise_size), dtype=torch.float, device=device)\n",
    "        g_in = torch.cat((noise,W_fixed),1)\n",
    "        A_fixed_gen = netG(g_in).detach().numpy()\n",
    "        errors = [sqrt(ot.wasserstein_1d(A_fixed_true[:,i],A_fixed_gen[:,i],p=2)) for i in range(a_dim)]\n",
    "        chen_training_wass_errors.append(errors)\n",
    "\n",
    "        # Test Chen discrepancy\n",
    "        W = torch.randn((4*batch_size, w_dim), dtype= torch.float, device=device)\n",
    "        noise = torch.randn((4*batch_size,noise_size), dtype=torch.float, device=device)\n",
    "        gen_in = torch.cat((noise,W),1)\n",
    "        A_gen = netG(gen_in)\n",
    "        w_a = torch.cat((W,A_gen.detach()),1)\n",
    "        ch_err = chen_error_2step(w_a)\n",
    "\n",
    "        # Print out partial results\n",
    "        pretty_errors = [\"{0:0.5f}\".format(i) for i in errors]\n",
    "        pretty_chen_errors = [\"{0:0.5f}\".format(i) for i in ch_err]\n",
    "        print(f\"iter: {chen_iters}/{num_Chen_iters},\\n errors: {pretty_errors}, \\n chen errors: {pretty_chen_errors}\")\n",
    "        # Save for plotting\n",
    "        chen_training_wass_errors.append(errors)\n",
    "        chen_training_chen_errors.append(ch_err)\n",
    "\n",
    "\n",
    "        # Early stopping checkpoint\n",
    "        error_sum = sum(errors)\n",
    "        if error_sum <= min_sum:\n",
    "            min_sum = error_sum\n",
    "            min_sum_errors = errors\n",
    "            min_sum_paramsG = copy.deepcopy(netG.state_dict())\n",
    "            min_sum_paramsD = copy.deepcopy(netD.state_dict())\n",
    "            print(\"Saved parameters\")\n",
    "\n",
    "    chen_iters += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Draw errors through iterations\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"2-Wasserstein distance of generated samples from the original samples for fixed W increment\")\n",
    "plt.plot(chen_training_wass_errors)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Wasserstein distance\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Time measurements\n",
    "\n",
    "W_fixed: torch.Tensor = torch.tensor([1.0,-0.5,-1.2,-0.3,0.7,0.2,-0.9,0.1,1.7])\n",
    "W_fixed = W_fixed[:w_dim].unsqueeze(1).transpose(1,0)\n",
    "W_fixed = W_fixed.expand((test_batch_size,w_dim))\n",
    "noise = torch.randn((test_batch_size,noise_size), dtype=torch.float, device=device)\n",
    "g_in = torch.cat((noise,W_fixed),1)\n",
    "netG.eval()\n",
    "start_time = timeit.default_timer()\n",
    "for i in range(100):\n",
    "    A_fixed_out=netG(g_in)\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(elapsed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Takes 34.2s to generate 6553600 samples (original GAN)\n",
    "Calling iterated_integrals(h = 1.0, err = 0.0005) 6553600-times takes 100.5s"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# a list that records trial results in the following form (lowest_errors, best_net_params)\n",
    "trial_results = []\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    # initialize nets\n",
    "    if which_model == 1:\n",
    "        netD = Discriminator1().to(device)\n",
    "        netG = Generator1().to(device)\n",
    "    elif which_model == 2:\n",
    "        netD = Discriminator2().to(device)\n",
    "        netG = Generator2().to(device)\n",
    "    elif which_model == 3:\n",
    "        netD = Discriminator3().to(device)\n",
    "        netG = Generator3().to(device)\n",
    "\n",
    "    netD.apply(weights_init)\n",
    "    netG.apply(weights_init)\n",
    "\n",
    "\n",
    "    # Initialise optimiser\n",
    "\n",
    "    if which_optimizer == 'Adam':\n",
    "        optG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        optD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    elif which_optimizer == 'RMSProp':\n",
    "        optG = torch.optim.RMSprop(netG.parameters(), lr=lr)\n",
    "        optD = torch.optim.RMSprop(netD.parameters(), lr=lr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}