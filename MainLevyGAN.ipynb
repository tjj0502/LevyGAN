{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "noise_size = 62\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 3\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "ngpu = 0\n",
    "\n",
    "weight_cliping_limit = 0.01\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "test_batch_size = 65536\n",
    "\n",
    "w_dim = 9\n",
    "\n",
    "data_dim = int(w_dim*(w_dim - 1)//2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def row_processer(row):\n",
    "    return np.array(row, dtype= np.float32)\n",
    "\n",
    "filename = f\"samples/samples_{w_dim}-dim.csv\"\n",
    "datapipe = dp.iter.FileOpener([filename], mode='b')\n",
    "datapipe = datapipe.parse_csv(delimiter=',')\n",
    "datapipe = datapipe.map(row_processer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset=datapipe, batch_size=batch_size, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4574e-01, -4.5351e-01, -4.4477e-01,  ..., -9.9213e-05,\n",
      "          1.1470e-02,  1.0801e-02],\n",
      "        [ 2.3683e-01, -4.9418e-02,  2.8505e-02,  ..., -2.5169e-02,\n",
      "          1.3289e-02, -1.4461e-02],\n",
      "        [ 1.5292e+00, -6.0493e-01,  2.3344e-01,  ...,  5.1749e-03,\n",
      "          1.6578e-02,  9.9204e-03],\n",
      "        ...,\n",
      "        [-9.5029e-01,  8.7256e-01, -1.4139e+00,  ...,  2.3413e-02,\n",
      "          1.3653e-02,  1.4888e-03],\n",
      "        [ 7.5400e-01,  1.5456e-01,  2.3939e+00,  ..., -7.3247e-03,\n",
      "          1.7868e-03, -2.0897e-03],\n",
      "        [-2.4747e-01, -3.0479e-01, -1.4944e+00,  ..., -2.0072e-02,\n",
      "          1.2993e-02, -2.9737e-03]])\n",
      "torch.Size([1024, 15])\n"
     ]
    }
   ],
   "source": [
    "d = next(iter(dataloader))\n",
    "print(d)\n",
    "print(d.shape)\n",
    "if d.size(1) != data_dim + w_dim:\n",
    "    print(\"!!!!!!!!!!!!!!!!!!!!!!!!! WRONG DATA DIMENSIONS !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    if classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim+noise_size,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(128,data_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim + data_dim,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(512,512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(512,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(128,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Generator(\n  (main): Sequential(\n    (0): Linear(in_features=67, out_features=512, bias=True)\n    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU()\n    (3): Linear(in_features=512, out_features=512, bias=True)\n    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU()\n    (6): Linear(in_features=512, out_features=128, bias=True)\n    (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU()\n    (9): Linear(in_features=128, out_features=10, bias=True)\n  )\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netD = Discriminator().to(device)\n",
    "netD.apply(weights_init)\n",
    "netG = Generator().to(device)\n",
    "netG.apply(weights_init)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "optG = torch.optim.Adam(netG.parameters(),lr = lr, betas=(beta1,0.999))\n",
    "optD = torch.optim.Adam(netD.parameters(), lr = lr, betas=(beta1,0.999))\n",
    "\n",
    "D_losses = []\n",
    "G_losses = []\n",
    "\n",
    "iters = 0\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/3, iter: 0,\n",
      "lossD_fake: 0.5025027990341187, lossD_real: 0.5025032758712769 lossG: 0.5025137066841125\n",
      "epoch: 0/3, iter: 100,\n",
      "lossD_fake: 0.5003982782363892, lossD_real: 0.49962788820266724 lossG: 0.5004345774650574\n",
      "epoch: 0/3, iter: 200,\n",
      "lossD_fake: 0.5004305839538574, lossD_real: 0.4995853900909424 lossG: 0.5004522800445557\n",
      "epoch: 0/3, iter: 300,\n",
      "lossD_fake: 0.5004465579986572, lossD_real: 0.49955469369888306 lossG: 0.5004684329032898\n",
      "epoch: 0/3, iter: 400,\n",
      "lossD_fake: 0.5004550814628601, lossD_real: 0.49953901767730713 lossG: 0.5004541873931885\n",
      "epoch: 0/3, iter: 500,\n",
      "lossD_fake: 0.5003911852836609, lossD_real: 0.4995414614677429 lossG: 0.5004033446311951\n",
      "epoch: 0/3, iter: 600,\n",
      "lossD_fake: 0.5003912448883057, lossD_real: 0.4995378255844116 lossG: 0.5004229545593262\n",
      "epoch: 0/3, iter: 700,\n",
      "lossD_fake: 0.5004489421844482, lossD_real: 0.49953314661979675 lossG: 0.500440776348114\n",
      "epoch: 0/3, iter: 800,\n",
      "lossD_fake: 0.5004638433456421, lossD_real: 0.4995088577270508 lossG: 0.5004743337631226\n",
      "epoch: 0/3, iter: 900,\n",
      "lossD_fake: 0.5004576444625854, lossD_real: 0.49949827790260315 lossG: 0.5004838109016418\n",
      "epoch: 0/3, iter: 1000,\n",
      "lossD_fake: 0.5004574060440063, lossD_real: 0.49949169158935547 lossG: 0.5004737377166748\n",
      "epoch: 0/3, iter: 1100,\n",
      "lossD_fake: 0.5004302263259888, lossD_real: 0.4995139539241791 lossG: 0.500449001789093\n",
      "epoch: 0/3, iter: 1200,\n",
      "lossD_fake: 0.5004289150238037, lossD_real: 0.49949169158935547 lossG: 0.5004564523696899\n",
      "epoch: 0/3, iter: 1300,\n",
      "lossD_fake: 0.5004560947418213, lossD_real: 0.49950921535491943 lossG: 0.5004763603210449\n",
      "epoch: 0/3, iter: 1400,\n",
      "lossD_fake: 0.5004411935806274, lossD_real: 0.49948275089263916 lossG: 0.5004650950431824\n",
      "epoch: 0/3, iter: 1500,\n",
      "lossD_fake: 0.5003978610038757, lossD_real: 0.49948790669441223 lossG: 0.500464916229248\n",
      "epoch: 0/3, iter: 1600,\n",
      "lossD_fake: 0.5004109740257263, lossD_real: 0.4994920492172241 lossG: 0.5004348754882812\n",
      "epoch: 0/3, iter: 1700,\n",
      "lossD_fake: 0.500424861907959, lossD_real: 0.49951687455177307 lossG: 0.5004439353942871\n",
      "epoch: 0/3, iter: 1800,\n",
      "lossD_fake: 0.5003873705863953, lossD_real: 0.499567449092865 lossG: 0.50035160779953\n",
      "epoch: 0/3, iter: 1900,\n",
      "lossD_fake: 0.5004069805145264, lossD_real: 0.4995596706867218 lossG: 0.5004015564918518\n",
      "epoch: 0/3, iter: 2000,\n",
      "lossD_fake: 0.5004116892814636, lossD_real: 0.4995281398296356 lossG: 0.5004168748855591\n",
      "epoch: 1/3, iter: 2100,\n",
      "lossD_fake: 0.5003505349159241, lossD_real: 0.49951088428497314 lossG: 0.5003571510314941\n",
      "epoch: 1/3, iter: 2200,\n",
      "lossD_fake: 0.500389814376831, lossD_real: 0.49954596161842346 lossG: 0.5003721714019775\n",
      "epoch: 1/3, iter: 2300,\n",
      "lossD_fake: 0.5003880262374878, lossD_real: 0.49954426288604736 lossG: 0.5003905296325684\n",
      "epoch: 1/3, iter: 2400,\n",
      "lossD_fake: 0.5003847479820251, lossD_real: 0.4995132088661194 lossG: 0.5003869533538818\n",
      "epoch: 1/3, iter: 2500,\n",
      "lossD_fake: 0.5004039406776428, lossD_real: 0.4994901716709137 lossG: 0.500436544418335\n",
      "epoch: 1/3, iter: 2600,\n",
      "lossD_fake: 0.5003638863563538, lossD_real: 0.49950358271598816 lossG: 0.5004329085350037\n",
      "epoch: 1/3, iter: 2700,\n",
      "lossD_fake: 0.5003933906555176, lossD_real: 0.4996035397052765 lossG: 0.5003002285957336\n",
      "epoch: 1/3, iter: 2800,\n",
      "lossD_fake: 0.5003460645675659, lossD_real: 0.4995875358581543 lossG: 0.5003806352615356\n",
      "epoch: 1/3, iter: 2900,\n",
      "lossD_fake: 0.500418484210968, lossD_real: 0.49953800439834595 lossG: 0.5004227757453918\n",
      "epoch: 1/3, iter: 3000,\n",
      "lossD_fake: 0.5004352331161499, lossD_real: 0.49953925609588623 lossG: 0.5004075169563293\n",
      "epoch: 1/3, iter: 3100,\n",
      "lossD_fake: 0.500427782535553, lossD_real: 0.4995875954627991 lossG: 0.5004035830497742\n",
      "epoch: 1/3, iter: 3200,\n",
      "lossD_fake: 0.5005103945732117, lossD_real: 0.4996025562286377 lossG: 0.5004916191101074\n",
      "epoch: 1/3, iter: 3300,\n",
      "lossD_fake: 0.5004934668540955, lossD_real: 0.499504417181015 lossG: 0.5004473924636841\n",
      "epoch: 1/3, iter: 3400,\n",
      "lossD_fake: 0.5004451870918274, lossD_real: 0.49955543875694275 lossG: 0.5004479289054871\n",
      "epoch: 1/3, iter: 3500,\n",
      "lossD_fake: 0.500418484210968, lossD_real: 0.49956214427948 lossG: 0.5004585981369019\n",
      "epoch: 1/3, iter: 3600,\n",
      "lossD_fake: 0.5002741813659668, lossD_real: 0.49955540895462036 lossG: 0.5003828406333923\n",
      "epoch: 1/3, iter: 3700,\n",
      "lossD_fake: 0.5003410577774048, lossD_real: 0.4995322525501251 lossG: 0.5004233121871948\n",
      "epoch: 1/3, iter: 3800,\n",
      "lossD_fake: 0.5004220604896545, lossD_real: 0.49953705072402954 lossG: 0.5003117918968201\n",
      "epoch: 1/3, iter: 3900,\n",
      "lossD_fake: 0.5003759860992432, lossD_real: 0.49958786368370056 lossG: 0.500414252281189\n",
      "epoch: 1/3, iter: 4000,\n",
      "lossD_fake: 0.5004767775535583, lossD_real: 0.4995044767856598 lossG: 0.5004895925521851\n",
      "epoch: 2/3, iter: 4100,\n",
      "lossD_fake: 0.5004372000694275, lossD_real: 0.49946850538253784 lossG: 0.500433087348938\n",
      "epoch: 2/3, iter: 4200,\n",
      "lossD_fake: 0.500300407409668, lossD_real: 0.49955061078071594 lossG: 0.5003671646118164\n",
      "epoch: 2/3, iter: 4300,\n",
      "lossD_fake: 0.5004951357841492, lossD_real: 0.499550998210907 lossG: 0.5004611015319824\n",
      "epoch: 2/3, iter: 4400,\n",
      "lossD_fake: 0.5004784464836121, lossD_real: 0.49947389960289 lossG: 0.5004886388778687\n",
      "epoch: 2/3, iter: 4500,\n",
      "lossD_fake: 0.5004588961601257, lossD_real: 0.4994531273841858 lossG: 0.5005251169204712\n",
      "epoch: 2/3, iter: 4600,\n",
      "lossD_fake: 0.5004986524581909, lossD_real: 0.49945029616355896 lossG: 0.5004935264587402\n",
      "epoch: 2/3, iter: 4700,\n",
      "lossD_fake: 0.5005174875259399, lossD_real: 0.49952301383018494 lossG: 0.5004663467407227\n",
      "epoch: 2/3, iter: 4800,\n",
      "lossD_fake: 0.5004521012306213, lossD_real: 0.499442994594574 lossG: 0.5004799365997314\n",
      "epoch: 2/3, iter: 4900,\n",
      "lossD_fake: 0.5004740357398987, lossD_real: 0.49953413009643555 lossG: 0.5004836320877075\n",
      "epoch: 2/3, iter: 5000,\n",
      "lossD_fake: 0.500489354133606, lossD_real: 0.49948829412460327 lossG: 0.5005202889442444\n",
      "epoch: 2/3, iter: 5100,\n",
      "lossD_fake: 0.5004680752754211, lossD_real: 0.49952223896980286 lossG: 0.5004751682281494\n",
      "epoch: 2/3, iter: 5200,\n",
      "lossD_fake: 0.5004256963729858, lossD_real: 0.49951720237731934 lossG: 0.5004130601882935\n",
      "epoch: 2/3, iter: 5300,\n",
      "lossD_fake: 0.5004135370254517, lossD_real: 0.4994717538356781 lossG: 0.5005074143409729\n",
      "epoch: 2/3, iter: 5400,\n",
      "lossD_fake: 0.5004539489746094, lossD_real: 0.499727725982666 lossG: 0.4999818205833435\n",
      "epoch: 2/3, iter: 5500,\n",
      "lossD_fake: 0.5004951357841492, lossD_real: 0.4994887709617615 lossG: 0.5004602670669556\n",
      "epoch: 2/3, iter: 5600,\n",
      "lossD_fake: 0.5004141330718994, lossD_real: 0.49952709674835205 lossG: 0.5004385113716125\n",
      "epoch: 2/3, iter: 5700,\n",
      "lossD_fake: 0.5003941059112549, lossD_real: 0.4994952082633972 lossG: 0.5004332065582275\n",
      "epoch: 2/3, iter: 5800,\n",
      "lossD_fake: 0.5003920197486877, lossD_real: 0.4994991719722748 lossG: 0.5004187822341919\n",
      "epoch: 2/3, iter: 5900,\n",
      "lossD_fake: 0.5004494786262512, lossD_real: 0.4995633661746979 lossG: 0.5003986954689026\n",
      "epoch: 2/3, iter: 6000,\n",
      "lossD_fake: 0.500403881072998, lossD_real: 0.49957144260406494 lossG: 0.5004016757011414\n",
      "epoch: 2/3, iter: 6100,\n",
      "lossD_fake: 0.5004443526268005, lossD_real: 0.4994643032550812 lossG: 0.5005195736885071\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        netD.zero_grad()\n",
    "\n",
    "        for p in netD.parameters():\n",
    "            p.data.clamp_(-weight_cliping_limit, weight_cliping_limit)\n",
    "\n",
    "\n",
    "        b_size = data.size(0)\n",
    "\n",
    "        out_D_real = netD(data)\n",
    "        lossDr = out_D_real.mean(0).view(1)\n",
    "        lossDr.backward(one)\n",
    "\n",
    "        W = data[:,:w_dim]\n",
    "        A_real = data[:,w_dim:(w_dim + data_dim)]\n",
    "        noise = torch.randn((b_size,noise_size), dtype=torch.float, device=device)\n",
    "        gen_in = torch.cat((noise,W),1)\n",
    "        generated_A = netG(gen_in)\n",
    "        fake_in = torch.cat((W,generated_A.detach()),1)\n",
    "\n",
    "        lossDf = netD(fake_in)\n",
    "        lossDf = lossDf.mean(0).view(1)\n",
    "        lossDf.backward(mone)\n",
    "        lossD = lossDr - lossDf\n",
    "        optD.step()\n",
    "\n",
    "        if i%10==0:\n",
    "            netG.zero_grad()\n",
    "\n",
    "            fake_in = torch.cat((W,generated_A),1)\n",
    "            lossG = netD(fake_in)\n",
    "            lossG = lossG.mean(0).view(1)\n",
    "            lossG.backward(one)\n",
    "            optG.step()\n",
    "\n",
    "        if iters%100 == 0:\n",
    "            print(f\"epoch: {epoch}/{num_epochs}, iter: {iters},\\nlossD_fake: {lossDf.item()}, lossD_real: {lossDr.item()} lossG: {lossG.item()}\")\n",
    "            G_losses.append(lossG.item())\n",
    "            D_losses.append(lossD.item())\n",
    "\n",
    "        iters += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000, -0.5000, -1.2000,  ..., -0.9000,  0.1000,  1.7000],\n",
      "        [ 1.0000, -0.5000, -1.2000,  ..., -0.9000,  0.1000,  1.7000],\n",
      "        [ 1.0000, -0.5000, -1.2000,  ..., -0.9000,  0.1000,  1.7000],\n",
      "        ...,\n",
      "        [ 1.0000, -0.5000, -1.2000,  ..., -0.9000,  0.1000,  1.7000],\n",
      "        [ 1.0000, -0.5000, -1.2000,  ..., -0.9000,  0.1000,  1.7000],\n",
      "        [ 1.0000, -0.5000, -1.2000,  ..., -0.9000,  0.1000,  1.7000]])\n"
     ]
    }
   ],
   "source": [
    "W_fixed: torch.Tensor = torch.tensor([1.0,-0.5,-1.2,-0.3,0.7,0.2,-0.9,0.1,1.7])\n",
    "W_fixed = W_fixed[:w_dim].unsqueeze(1).transpose(1,0)\n",
    "W_fixed = W_fixed.expand((test_batch_size,w_dim))\n",
    "print(W_fixed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65536, 10)\n"
     ]
    }
   ],
   "source": [
    "noise = torch.randn((test_batch_size,noise_size), dtype=torch.float, device=device)\n",
    "g_in = torch.cat((noise,W_fixed),1)\n",
    "A_fixed_gen = netG(g_in).detach().numpy()\n",
    "print(A_fixed_gen.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#output = torch.cat((W_fixed,A_fixed_gen), 1)\n",
    "#print(output.shape)\n",
    "# np.savetxt(\"fixed_GAN_out_2d.csv\", output.detach()[:,2], delimiter=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003986282303522681\n",
      "0.015288523266045864\n",
      "0.01639928861573666\n",
      "0.014736991408361905\n",
      "0.012501982121504222\n",
      "0.018853810314580038\n",
      "0.002594853676512707\n",
      "0.006951561533124371\n",
      "0.0139525881855331\n",
      "0.006613752276877162\n"
     ]
    }
   ],
   "source": [
    "A_fixed_gen = A_fixed_gen\n",
    "test_filename = f\"samples/fixed_samples_{w_dim}-dim.csv\"\n",
    "samples = np.genfromtxt(test_filename,dtype=float,delimiter=',',)\n",
    "A_fixed_true = samples[:,w_dim:(w_dim+data_dim)]\n",
    "for i in range(data_dim):\n",
    "    true_col = A_fixed_true[:,i]\n",
    "    generated_col = A_fixed_gen[:,i]\n",
    "    dist = ot.wasserstein_1d(true_col,generated_col,p=2)\n",
    "    print(dist)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}