{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import copy\n",
    "from math import sqrt\n",
    "\n",
    "from torch.autograd import grad as torch_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "noise_size = 62\n",
    "\n",
    "# Number of training epochs using classical training\n",
    "num_epochs = 20\n",
    "\n",
    "# Number of iterations of Chen training\n",
    "num_Chen_iters = 5000\n",
    "\n",
    "# 'Adam' of 'RMSProp'\n",
    "which_optimizer = 'Adam'\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lrG = 0.000005\n",
    "lrD = 0.00005\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0\n",
    "\n",
    "beta2 = 0.99\n",
    "\n",
    "ngpu = 0\n",
    "\n",
    "# To keep the criterion Lipschitz\n",
    "weight_cliping_limit = 0.01\n",
    "\n",
    "# for gradient penalty\n",
    "gp_weight = 10.0\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "test_batch_size = 16384\n",
    "\n",
    "w_dim = 4\n",
    "\n",
    "a_dim = int(w_dim*(w_dim - 1)//2)\n",
    "\n",
    "# if 1 use GAN1, if 2 use GAN2, etc.\n",
    "which_model = 2\n",
    "\n",
    "# slope for LeakyReLU\n",
    "leakyReLU_slope = 0.2\n",
    "\n",
    "# this gives the option to rum the training process multiple times with differently initialised GANs\n",
    "#num_trials = 1\n",
    "\n",
    "num_tests_for2d = 8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate T and M\n",
    "\n",
    "def generate_signs(n: int):\n",
    "    lst = []\n",
    "    for i in range(2**n):\n",
    "        binary_exp = list(bin(i)[2:])\n",
    "        lst.append((n-len(binary_exp))*[0]+binary_exp)\n",
    "\n",
    "    res = 2*np.array(lst, dtype=float) - np.ones((2**n,n), dtype=float)\n",
    "    return res\n",
    "\n",
    "signs = generate_signs(w_dim)\n",
    "\n",
    "first_dim = []\n",
    "second_dim = []\n",
    "third_dim = []\n",
    "fourth_dim = []\n",
    "values = []\n",
    "M_list = []\n",
    "\n",
    "for s in range(len(signs)):\n",
    "    idx = 0\n",
    "    M_row = []\n",
    "    for i in range(w_dim):\n",
    "        for j in range(i+1,w_dim):\n",
    "            first_dim.append(s)\n",
    "            second_dim.append(idx)\n",
    "            third_dim.append(i)\n",
    "            fourth_dim.append(j)\n",
    "            values.append(-1*signs[s,j].item())\n",
    "            first_dim.append(s)\n",
    "            second_dim.append(idx)\n",
    "            third_dim.append(j)\n",
    "            fourth_dim.append(i)\n",
    "            values.append(signs[s,j].item())\n",
    "            idx+=1\n",
    "            M_row.append(signs[s,j].item() * signs[s,i].item())\n",
    "    M_list.append(M_row)\n",
    "\n",
    "indices = [first_dim,second_dim,third_dim,fourth_dim]\n",
    "T = torch.sparse_coo_tensor(indices=indices,values=values, size = (len(signs),a_dim,w_dim,w_dim)).to_dense()\n",
    "\n",
    "M = torch.tensor(M_list).unsqueeze(1)\n",
    "\n",
    "\n",
    "# A function that takes W, H and B (B is the Levy Area of the Brownian Bridge) and computes A = WTH+MB\n",
    "# where the hell is maribor anyway?\n",
    "def wthmb(w_in: torch.Tensor, h_in: torch.Tensor, b_in: torch.Tensor):\n",
    "    assert w_in.shape == (batch_size,a_dim) and h_in.shape == (batch_size, w_dim) and b_in.shape == (batch_size, a_dim)\n",
    "    _W = w_in.view(1,1,batch_size,w_dim)\n",
    "    _H = h_in.view(batch_size,w_dim,1)\n",
    "    _B = b_in.view(1,batch_size,a_dim)\n",
    "    WT = torch.matmul(_W, T).permute(0,2,1,3)\n",
    "    WTH = torch.matmul(WT, _H).squeeze()\n",
    "    MB = torch.mul(M,_B)\n",
    "    return torch.flatten(WTH + MB, start_dim=0,end_dim=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
