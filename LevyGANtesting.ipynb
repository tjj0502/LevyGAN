{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torchdata.datapipes as dp\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "import copy\n",
    "from math import sqrt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "noise_size = 24\n",
    "\n",
    "# Number of training epochs using classical training\n",
    "num_epochs = 1\n",
    "\n",
    "# Number of iterations of Chen training\n",
    "num_Chen_iters = 0\n",
    "\n",
    "# 'Adam' of 'RMSProp'\n",
    "which_optimizer = 'RMSProp'\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.00002\n",
    "\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "ngpu = 0\n",
    "\n",
    "# To keep the criterion Lipschitz\n",
    "weight_cliping_limit = 0.01\n",
    "\n",
    "batch_size = 1024\n",
    "\n",
    "test_batch_size = 65536\n",
    "\n",
    "w_dim = 3\n",
    "\n",
    "a_dim = int(w_dim*(w_dim - 1)//2)\n",
    "\n",
    "# if 1 use GAN1, if 2 use GAN2, etc.\n",
    "which_model = 3\n",
    "\n",
    "# slope for LeakyReLU\n",
    "leakyReLU_slope = 0.2\n",
    "\n",
    "# this gives the option to rum the training process multiple times with differently initialised GANs\n",
    "num_trials = 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# CHEN RELATION\n",
    "# Levy-area satisfies a version of the Chen relation (see Chen_relation.pdf) and is the unique distribution which satisfies this version of the relation\n",
    "\n",
    "def chen_combine(w_a_in: torch.TensorType):\n",
    "    # the batch dimension of the inputs will be quartered\n",
    "    out_size = w_a_in.size(0) // 2\n",
    "    assert 2 * out_size == w_a_in.size(0)\n",
    "    assert w_a_in.size(1) == w_dim + a_dim\n",
    "\n",
    "    # w_0_s is from 0 to t/2 and w_s_t is from t/2 to t\n",
    "    w_0_s, w_s_t = w_a_in.chunk(2)\n",
    "    result = torch.clone(w_0_s + w_s_t)\n",
    "    result[:, :w_dim] = sqrt(0.5) * result[:, :w_dim]\n",
    "    result[:, w_dim:(w_dim + a_dim)] = 0.5 * result[:, w_dim:(w_dim + a_dim)]\n",
    "\n",
    "    idx = w_dim\n",
    "    for k in range(w_dim - 1):\n",
    "        for l in range(k + 1, w_dim):\n",
    "            correction_term = 0.25 * (w_0_s[:, k] * w_s_t[:, l] - w_0_s[:, l] * w_s_t[:, k])\n",
    "            result[:, idx] += correction_term\n",
    "            idx += 1\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# prints the 2-Wasserstein distances (in each of the Levy-area dimensions) between the input and chen_combine(chen_combine(input))\n",
    "# The idea behind this is that Levy-area is the unique distribution which is close to chen_combine of itself\n",
    "# Indeed this is experimentally confirmed in test.ipynb\n",
    "\n",
    "def chen_error_2step(w_a_in: torch.TensorType):\n",
    "    combined_data = chen_combine(w_a_in)\n",
    "    combined_data = chen_combine(combined_data)\n",
    "    return [sqrt(ot.wasserstein_1d(combined_data[:, w_dim + i], w_a_in[:, w_dim + i], p=2)) for i in range(a_dim)]\n",
    "\n",
    "\n",
    "# create dataloader for samples\n",
    "\n",
    "def row_processer(row):\n",
    "    return np.array(row, dtype=np.float32)\n",
    "\n",
    "\n",
    "filename = f\"samples/samples_{w_dim}-dim.csv\"\n",
    "datapipe = dp.iter.FileOpener([filename], mode='b')\n",
    "datapipe = datapipe.parse_csv(delimiter=',')\n",
    "datapipe = datapipe.map(row_processer)\n",
    "dataloader = DataLoader(dataset=datapipe, batch_size=batch_size, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    if classname.find(\"BatchNorm\") != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "# GAN 1\n",
    "\n",
    "class Generator1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator1, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim + noise_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, a_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class Discriminator1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator1, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim + a_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(512, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "\n",
    "# GAN 2\n",
    "\n",
    "class Generator2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator2, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim + noise_size, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, a_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class Discriminator2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator2, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim + a_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "# GAN 3\n",
    "\n",
    "class Generator3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator3, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim + noise_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(128, a_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class Discriminator3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator3, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(w_dim + a_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(leakyReLU_slope),\n",
    "\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "# A fixed W increment for testing purposes\n",
    "W_fixed: torch.Tensor = torch.tensor([1.0,-0.5,-1.2,-0.3,0.7,0.2,-0.9,0.1,1.7])\n",
    "\n",
    "# function that lists which pairs of W_fixed features are used for each dimension of a_dim\n",
    "def list_pairs(m):\n",
    "    fixed_w_list = [1.0,-0.5,-1.2,-0.3,0.7,0.2,-0.9,0.1,1.7]\n",
    "    lst =[]\n",
    "    for k in range(m):\n",
    "        for l in range(k+1,m):\n",
    "            lst.append((fixed_w_list[k],fixed_w_list[l]))\n",
    "\n",
    "    return lst\n",
    "\n",
    "W_fixed = W_fixed[:w_dim].unsqueeze(1).transpose(1,0)\n",
    "W_fixed = W_fixed.expand((test_batch_size,w_dim))\n",
    "\n",
    "# Load \"true\" samples generated from this fixed W increment\n",
    "test_filename = f\"samples/fixed_samples_{w_dim}-dim.csv\"\n",
    "A_fixed_true = np.genfromtxt(test_filename,dtype=float,delimiter=',',)\n",
    "A_fixed_true = A_fixed_true[:,w_dim:(w_dim+a_dim)]\n",
    "\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial: 0/3 epoch: 0/1, iter: 0,\n",
      " errors: ['0.16680', '0.16885', '0.37460']\n",
      "Saved parameters\n",
      "trial: 0/3 epoch: 0/1, iter: 100,\n",
      " errors: ['0.16982', '0.03133', '0.36048']\n",
      "Saved parameters\n",
      "trial: 0/3 epoch: 0/1, iter: 200,\n",
      " errors: ['0.16012', '0.05688', '0.34202']\n",
      "Saved parameters\n",
      "trial: 0/3 epoch: 0/1, iter: 300,\n",
      " errors: ['0.16882', '0.06927', '0.33482']\n",
      "trial: 0/3 epoch: 0/1, iter: 400,\n",
      " errors: ['0.17020', '0.03923', '0.33421']\n",
      "Saved parameters\n",
      "trial: 0/3 epoch: 0/1, iter: 500,\n",
      " errors: ['0.15612', '0.04165', '0.34268']\n",
      "Saved parameters\n",
      "trial: 0/3 epoch: 0/1, iter: 600,\n",
      " errors: ['0.15908', '0.03160', '0.34305']\n",
      "Saved parameters\n",
      "trial: 0/3 epoch: 0/1, iter: 700,\n",
      " errors: ['0.18425', '0.02945', '0.34132']\n",
      "trial: 0/3 epoch: 0/1, iter: 800,\n",
      " errors: ['0.18044', '0.04134', '0.34291']\n",
      "trial: 0/3 epoch: 0/1, iter: 900,\n",
      " errors: ['0.16717', '0.05569', '0.35311']\n",
      "trial: 0/3 epoch: 0/1, iter: 1000,\n",
      " errors: ['0.17278', '0.05455', '0.34081']\n",
      "trial: 0/3 epoch: 0/1, iter: 1100,\n",
      " errors: ['0.18240', '0.06742', '0.33486']\n",
      "trial: 0/3 epoch: 0/1, iter: 1200,\n",
      " errors: ['0.19754', '0.06975', '0.33956']\n",
      "trial: 0/3 epoch: 0/1, iter: 1300,\n",
      " errors: ['0.20260', '0.07430', '0.33609']\n",
      "trial: 0/3 epoch: 0/1, iter: 1400,\n",
      " errors: ['0.18407', '0.08425', '0.34001']\n",
      "trial: 0/3 epoch: 0/1, iter: 1500,\n",
      " errors: ['0.16908', '0.09256', '0.34566']\n",
      "trial: 0/3 epoch: 0/1, iter: 1600,\n",
      " errors: ['0.16586', '0.09508', '0.34727']\n",
      "trial: 0/3 epoch: 0/1, iter: 1700,\n",
      " errors: ['0.16555', '0.09482', '0.34609']\n",
      "trial: 0/3 epoch: 0/1, iter: 1800,\n",
      " errors: ['0.17141', '0.09679', '0.33910']\n",
      "trial: 0/3 epoch: 0/1, iter: 1900,\n",
      " errors: ['0.18805', '0.09682', '0.34036']\n",
      "trial: 0/3 epoch: 0/1, iter: 2000,\n",
      " errors: ['0.19622', '0.10132', '0.33836']\n",
      "trial: 1/3 epoch: 0/1, iter: 0,\n",
      " errors: ['0.26680', '0.17871', '0.26415']\n",
      "Saved parameters\n",
      "trial: 1/3 epoch: 0/1, iter: 100,\n",
      " errors: ['0.26857', '0.03624', '0.24492']\n",
      "Saved parameters\n",
      "trial: 1/3 epoch: 0/1, iter: 200,\n",
      " errors: ['0.23785', '0.06823', '0.23596']\n",
      "Saved parameters\n",
      "trial: 1/3 epoch: 0/1, iter: 300,\n",
      " errors: ['0.23230', '0.05811', '0.23055']\n",
      "Saved parameters\n",
      "trial: 1/3 epoch: 0/1, iter: 400,\n",
      " errors: ['0.23997', '0.06710', '0.23065']\n",
      "trial: 1/3 epoch: 0/1, iter: 500,\n",
      " errors: ['0.24522', '0.05208', '0.22925']\n",
      "trial: 1/3 epoch: 0/1, iter: 600,\n",
      " errors: ['0.25006', '0.06654', '0.23494']\n",
      "trial: 1/3 epoch: 0/1, iter: 700,\n",
      " errors: ['0.25760', '0.03491', '0.22995']\n",
      "trial: 1/3 epoch: 0/1, iter: 800,\n",
      " errors: ['0.24918', '0.04024', '0.23458']\n",
      "trial: 1/3 epoch: 0/1, iter: 900,\n",
      " errors: ['0.25307', '0.04688', '0.23844']\n",
      "trial: 1/3 epoch: 0/1, iter: 1000,\n",
      " errors: ['0.25744', '0.05890', '0.23901']\n",
      "trial: 1/3 epoch: 0/1, iter: 1100,\n",
      " errors: ['0.25983', '0.06634', '0.23202']\n",
      "trial: 1/3 epoch: 0/1, iter: 1200,\n",
      " errors: ['0.25906', '0.06968', '0.22855']\n",
      "trial: 1/3 epoch: 0/1, iter: 1300,\n",
      " errors: ['0.25379', '0.07168', '0.22857']\n",
      "trial: 1/3 epoch: 0/1, iter: 1400,\n",
      " errors: ['0.24329', '0.07818', '0.22783']\n",
      "trial: 1/3 epoch: 0/1, iter: 1500,\n",
      " errors: ['0.24126', '0.08458', '0.22774']\n",
      "trial: 1/3 epoch: 0/1, iter: 1600,\n",
      " errors: ['0.24459', '0.08877', '0.23198']\n",
      "trial: 1/3 epoch: 0/1, iter: 1700,\n",
      " errors: ['0.24603', '0.09900', '0.23314']\n",
      "trial: 1/3 epoch: 0/1, iter: 1800,\n",
      " errors: ['0.25065', '0.10128', '0.23278']\n",
      "trial: 1/3 epoch: 0/1, iter: 1900,\n",
      " errors: ['0.26154', '0.09939', '0.22690']\n",
      "trial: 1/3 epoch: 0/1, iter: 2000,\n",
      " errors: ['0.25585', '0.10428', '0.22744']\n",
      "trial: 2/3 epoch: 0/1, iter: 0,\n",
      " errors: ['0.13463', '0.33840', '0.21101']\n",
      "Saved parameters\n",
      "trial: 2/3 epoch: 0/1, iter: 100,\n",
      " errors: ['0.13559', '0.25525', '0.19483']\n",
      "Saved parameters\n",
      "trial: 2/3 epoch: 0/1, iter: 200,\n",
      " errors: ['0.11274', '0.25038', '0.18444']\n",
      "Saved parameters\n",
      "trial: 2/3 epoch: 0/1, iter: 300,\n",
      " errors: ['0.11335', '0.24818', '0.18052']\n",
      "Saved parameters\n",
      "trial: 2/3 epoch: 0/1, iter: 400,\n",
      " errors: ['0.11394', '0.24731', '0.18415']\n",
      "trial: 2/3 epoch: 0/1, iter: 500,\n",
      " errors: ['0.12149', '0.24682', '0.18350']\n",
      "trial: 2/3 epoch: 0/1, iter: 600,\n",
      " errors: ['0.12680', '0.24593', '0.18990']\n",
      "trial: 2/3 epoch: 0/1, iter: 700,\n",
      " errors: ['0.13914', '0.23751', '0.18776']\n",
      "trial: 2/3 epoch: 0/1, iter: 800,\n",
      " errors: ['0.13942', '0.23798', '0.18763']\n",
      "trial: 2/3 epoch: 0/1, iter: 900,\n",
      " errors: ['0.14402', '0.23366', '0.19502']\n",
      "trial: 2/3 epoch: 0/1, iter: 1000,\n",
      " errors: ['0.15262', '0.23637', '0.19276']\n",
      "trial: 2/3 epoch: 0/1, iter: 1100,\n",
      " errors: ['0.15995', '0.23478', '0.19074']\n",
      "trial: 2/3 epoch: 0/1, iter: 1200,\n",
      " errors: ['0.15732', '0.23860', '0.19118']\n",
      "trial: 2/3 epoch: 0/1, iter: 1300,\n",
      " errors: ['0.14251', '0.23660', '0.19371']\n",
      "trial: 2/3 epoch: 0/1, iter: 1400,\n",
      " errors: ['0.13841', '0.23706', '0.19410']\n",
      "trial: 2/3 epoch: 0/1, iter: 1500,\n",
      " errors: ['0.13507', '0.24525', '0.19633']\n",
      "trial: 2/3 epoch: 0/1, iter: 1600,\n",
      " errors: ['0.13512', '0.24596', '0.19664']\n",
      "trial: 2/3 epoch: 0/1, iter: 1700,\n",
      " errors: ['0.13481', '0.25064', '0.19411']\n",
      "trial: 2/3 epoch: 0/1, iter: 1800,\n",
      " errors: ['0.13657', '0.25087', '0.20012']\n",
      "trial: 2/3 epoch: 0/1, iter: 1900,\n",
      " errors: ['0.13263', '0.24473', '0.19828']\n",
      "trial: 2/3 epoch: 0/1, iter: 2000,\n",
      " errors: ['0.13180', '0.24610', '0.19820']\n"
     ]
    }
   ],
   "source": [
    "# a list that records trial results in the following form (lowest_errors, best_net_params)\n",
    "trial_results = []\n",
    "best_trial_min_sum = min_sum = float('inf')\n",
    "best_trial_params = None\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    # initialize nets\n",
    "    if which_model == 1:\n",
    "        netD = Discriminator1().to(device)\n",
    "        netG = Generator1().to(device)\n",
    "    if which_model == 2:\n",
    "        netD = Discriminator2().to(device)\n",
    "        netG = Generator2().to(device)\n",
    "    elif which_model == 3:\n",
    "        netD = Discriminator3().to(device)\n",
    "        netG = Generator3().to(device)\n",
    "\n",
    "    netD.apply(weights_init)\n",
    "    netG.apply(weights_init)\n",
    "\n",
    "\n",
    "    # Initialise optimiser\n",
    "\n",
    "    if which_optimizer == 'Adam':\n",
    "        optG = torch.optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        optD = torch.optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "    elif which_optimizer == 'RMSProp':\n",
    "        optG = torch.optim.RMSprop(netG.parameters(), lr=lr)\n",
    "        optD = torch.optim.RMSprop(netD.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    # Prepare early stopping\n",
    "\n",
    "    min_sum = float('inf')\n",
    "    min_sum_errors = [1.0 for i in range(a_dim)]\n",
    "    min_sum_paramsG = copy.deepcopy(netG.state_dict())\n",
    "    min_sum_paramsD = copy.deepcopy(netD.state_dict())\n",
    "\n",
    "    # Start classical training\n",
    "\n",
    "    iters = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        for i, data in enumerate(dataloader):\n",
    "            netD.zero_grad()\n",
    "\n",
    "            # weight clipping so critic is lipschitz\n",
    "            for p in netD.parameters():\n",
    "                p.data.clamp_(-weight_cliping_limit, weight_cliping_limit)\n",
    "\n",
    "            # check actual batch size (last batch could be shorter)\n",
    "            b_size = data.size(0)\n",
    "\n",
    "            # Train Discriminator\n",
    "            # first on real data\n",
    "            out_D_real = netD(data)\n",
    "            lossDr = out_D_real.mean(0).view(1)\n",
    "            lossDr.backward(one)\n",
    "\n",
    "            # then on fake samples\n",
    "            # data has shape (b_size, w_dim + a_dim) where w_dim are the dimensions of the driving BM and a_dim is the dim of Levy Areas\n",
    "            W = data[:,:w_dim]\n",
    "            A_real = data[:,w_dim:(w_dim + a_dim)]\n",
    "            noise = torch.randn((b_size,noise_size), dtype=torch.float, device=device)\n",
    "            gen_in = torch.cat((noise,W),1)\n",
    "            # generate fake data\n",
    "            generated_A = netG(gen_in)\n",
    "            fake_in = torch.cat((W,generated_A.detach()),1)\n",
    "\n",
    "            lossDf = netD(fake_in)\n",
    "            lossDf = lossDf.mean(0).view(1)\n",
    "            lossDf.backward(mone)\n",
    "            lossD = lossDr - lossDf\n",
    "            optD.step()\n",
    "\n",
    "            # train Generator every 5 iterations\n",
    "            if iters%5 == 0:\n",
    "                netG.zero_grad()\n",
    "\n",
    "                fake_in = torch.cat((W,generated_A),1)\n",
    "                lossG = netD(fake_in)\n",
    "                lossG = lossG.mean(0).view(1)\n",
    "                lossG.backward(one)\n",
    "                optG.step()\n",
    "\n",
    "            if iters%100 == 0:\n",
    "                # Test Wasserstein error for fixed W\n",
    "                noise = torch.randn((test_batch_size,noise_size), dtype=torch.float, device=device)\n",
    "                g_in = torch.cat((noise,W_fixed),1)\n",
    "                A_fixed_gen = netG(g_in).detach().numpy()\n",
    "                errors = [sqrt(ot.wasserstein_1d(A_fixed_true[:,i],A_fixed_gen[:,i],p=2)) for i in range(a_dim)]\n",
    "\n",
    "                # Print out partial results\n",
    "                pretty_errors = [\"{0:0.5f}\".format(i) for i in errors]\n",
    "                # pretty_chen_errors = [\"{0:0.5f}\".format(i) for i in ch_err]\n",
    "                print(f\"trial: {trial}/{num_trials},  epoch: {epoch}/{num_epochs}, iter: {iters},\\n errors: {pretty_errors}\")\n",
    "\n",
    "                # Early stopping checkpoint\n",
    "                error_sum = sum(errors)\n",
    "                if error_sum <= min_sum:\n",
    "                    min_sum = error_sum\n",
    "                    min_sum_errors = errors\n",
    "                    min_sum_paramsG = copy.deepcopy(netG.state_dict())\n",
    "                    min_sum_paramsD = copy.deepcopy(netD.state_dict())\n",
    "                    print(\"Saved parameters\")\n",
    "\n",
    "            iters += 1\n",
    "\n",
    "\n",
    "    # end of trial\n",
    "    # record trial results\n",
    "\n",
    "    result = (min_sum_errors, min_sum_paramsG, min_sum_paramsD)\n",
    "    trial_results.append(result)\n",
    "\n",
    "    if min_sum < best_trial_min_sum:\n",
    "        best_trial_min_sum = min_sum\n",
    "        best_trial_params = (min_sum_paramsG, min_sum_paramsD)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# save the parameters of the best trial\n",
    "best_paramsG, best_paramsD = best_trial_params\n",
    "torch.save(best_paramsG, f'model_saves/GAN{which_model}_{w_dim}d_{num_epochs}epochs_generator.pt')\n",
    "torch.save(best_paramsD, f'model_saves/GAN{which_model}_{w_dim}d_{num_epochs}epochs_discriminator.pt')\n",
    "file_for_results = open(f'testing_results/GAN{which_model}_{w_dim}d_{num_epochs}epochs_{which_optimizer}_{lr}lr_results.obj', 'wb+')\n",
    "pickle.dump(trial_results, file_for_results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0.15907601114533243, 0.23229677199592028, 0.11334680191976482], 1: [0.0316040695020516, 0.05810625830459352, 0.2481779098450483], 2: [0.3430457774496784, 0.23054882642366187, 0.18052393973942188]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_per_adim = {i: [] for i in range(a_dim)}\n",
    "\n",
    "for res in trial_results:\n",
    "    errs, paramsG, paramsD = res\n",
    "    for i, err in enumerate(errs):\n",
    "        results_per_adim[i].append(err)\n",
    "\n",
    "print(results_per_adim)\n",
    "\n",
    "results_per_adim = [results_per_adim[i] for i in range(a_dim)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.eventplot(results_per_adim, orientation= 'vertical')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "def list_pairs(m):\n",
    "    fixed_w_list = [1.0,-0.5,-1.2,-0.3,0.7,0.2,-0.9,0.1,1.7]\n",
    "    lst =[]\n",
    "    for k in range(m):\n",
    "        for l in range(k+1,m):\n",
    "            lst.append((fixed_w_list[k],fixed_w_list[l]))\n",
    "\n",
    "    return lst\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.eventplot(results_per_adim, orientation= 'vertical')\n",
    "ax.set_xticks(range(a_dim),list_pairs(w_dim))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}